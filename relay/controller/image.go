package controller

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"math"
	"mime/multipart"
	"net/http"
	"net/textproto"
	"net/url"
	"path/filepath"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/songquanpeng/one-api/common"
	"github.com/songquanpeng/one-api/common/logger"
	"github.com/songquanpeng/one-api/model"
	"github.com/songquanpeng/one-api/relay/channel/gemini"
	"github.com/songquanpeng/one-api/relay/channel/keling"
	"github.com/songquanpeng/one-api/relay/channel/openai"
	"github.com/songquanpeng/one-api/relay/channel/vertexai"
	"github.com/songquanpeng/one-api/relay/helper"
	relaymodel "github.com/songquanpeng/one-api/relay/model"
	"github.com/songquanpeng/one-api/relay/util"

	"github.com/gin-gonic/gin"
)

func RelayImageHelper(c *gin.Context, relayMode int) *relaymodel.ErrorWithStatusCode {

	startTime := time.Now()
	ctx := c.Request.Context()

	channelId := c.GetInt("channel_id")
	userId := c.GetInt("id")

	logger.Infof(ctx, "RelayImageHelper START: relayMode=%d, channelId=%d, userId=%d, path=%s",
		relayMode, channelId, userId, c.Request.URL.Path)

	// è·å– meta ä¿¡æ¯ç”¨äºè°ƒè¯•
	meta := util.GetRelayMeta(c)

	// VertexAI é…ç½®è°ƒè¯•ä¿¡æ¯
	if meta.ChannelType == common.ChannelTypeVertexAI {
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] =====ã€VertexAIæ¸ é“é…ç½®ä¿¡æ¯ã€‘=====")
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] ChannelId: %d, ChannelType: %d", meta.ChannelId, meta.ChannelType)
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] IsMultiKey: %v, KeyIndex: %v", meta.IsMultiKey, meta.KeyIndex)
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] Keysæ•°é‡: %d, ActualAPIKeyé•¿åº¦: %d", len(meta.Keys), len(meta.ActualAPIKey))
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] Config.Region: '%s', Config.VertexAIProjectID: '%s'", meta.Config.Region, meta.Config.VertexAIProjectID)
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] Config.VertexAIADCæ˜¯å¦ä¸ºç©º: %v", meta.Config.VertexAIADC == "")
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] BaseURL: '%s'", meta.BaseURL)
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] =============================")
	}

	// æ£€æŸ¥å‡½æ•°å¼€å§‹æ—¶çš„ä¸Šä¸‹æ–‡çŠ¶æ€
	if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
		logger.Debugf(ctx, "RelayImageHelper: ENTRY - admin_channel_history exists: %v", channelHistoryInterface)
	}
	// æ£€æŸ¥å†…å®¹ç±»å‹
	contentType := c.GetHeader("Content-Type")
	isFormRequest := strings.Contains(contentType, "multipart/form-data") || strings.Contains(contentType, "application/x-www-form-urlencoded")

	// è·å–åŸºæœ¬çš„è¯·æ±‚ä¿¡æ¯ï¼Œä½†ä¸æ¶ˆè´¹è¯·æ±‚ä½“
	imageRequest, err := getImageRequest(c, meta.Mode)
	if err != nil {
		logger.Errorf(ctx, "getImageRequest failed: %s", err.Error())
		return openai.ErrorWrapper(err, "invalid_image_request", http.StatusBadRequest)
	}

	// map model name
	var isModelMapped bool
	meta.OriginModelName = imageRequest.Model
	imageRequest.Model, isModelMapped = util.GetMappedModelName(imageRequest.Model, meta.ModelMapping)
	meta.ActualModelName = imageRequest.Model

	imageCostRatio, err := getImageCostRatio(imageRequest)
	if err != nil {
		return openai.ErrorWrapper(err, "get_image_cost_ratio_failed", http.StatusInternalServerError)
	}

	var fullRequestURL string
	requestURL := c.Request.URL.String()
	fullRequestURL = util.GetFullRequestURL(meta.BaseURL, requestURL, meta.ChannelType)
	if meta.ChannelType == common.ChannelTypeAzure {
		apiVersion := util.GetAzureAPIVersion(c)
		fullRequestURL = fmt.Sprintf("%s/openai/deployments/%s/images/generations?api-version=%s", meta.BaseURL, imageRequest.Model, apiVersion)
	}
	if meta.ChannelType == 27 { //minimax
		fullRequestURL = fmt.Sprintf("%s/v1/image_generation", meta.BaseURL)
	}
	if meta.ChannelType == 40 { //doubao (å­—èŠ‚è·³åŠ¨è±†åŒ…)
		fullRequestURL = fmt.Sprintf("%s/api/v3/images/generations", meta.BaseURL)
	}

	var requestBody io.Reader
	var req *http.Request

	if isFormRequest {
		// å¯¹äºè¡¨å•è¯·æ±‚ï¼Œæˆ‘ä»¬éœ€è¦ç‰¹æ®Šå¤„ç†
		if strings.Contains(contentType, "multipart/form-data") {
			// è§£æåŸå§‹è¡¨å•
			if err := c.Request.ParseMultipartForm(32 << 20); err != nil { // 32MB
				return openai.ErrorWrapper(err, "parse_multipart_form_failed", http.StatusBadRequest)
			}

			// æ£€æŸ¥æ˜¯å¦æ˜¯ Gemini æ¨¡å‹çš„ form è¯·æ±‚ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†è½¬æ¢ä¸º JSON
			if strings.HasPrefix(imageRequest.Model, "gemini") {
				return handleGeminiFormRequest(c, ctx, imageRequest, meta, fullRequestURL)
			}

			// å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œç»§ç»­åŸæœ‰çš„ form è½¬å‘é€»è¾‘
			// åˆ›å»ºä¸€ä¸ªæ–°çš„multipartè¡¨å•
			body := &bytes.Buffer{}
			writer := multipart.NewWriter(body)

			// æ£€æŸ¥æ˜¯å¦æ˜¯ Gemini æ¨¡å‹
			isGemini := strings.HasPrefix(imageRequest.Model, "gemini")

			// æ·»åŠ æ‰€æœ‰è¡¨å•å­—æ®µ
			for key, values := range c.Request.MultipartForm.Value {
				for _, value := range values {
					// å¦‚æœæ¨¡å‹è¢«æ˜ å°„ï¼Œåˆ™æ›´æ–°modelå­—æ®µ
					if key == "model" && isModelMapped {
						writer.WriteField(key, imageRequest.Model)
					} else if isGemini && key == "response_format" {
						// Gemini ä¸æ”¯æŒ response_format å‚æ•°ï¼Œè·³è¿‡è¯¥å‚æ•°
						logger.Debugf(ctx, "Skipping response_format parameter for Gemini model (value: %s)", value)
						continue
					} else {
						writer.WriteField(key, value)
					}
				}
			}

			// æ·»åŠ æ‰€æœ‰æ–‡ä»¶
			for key, fileHeaders := range c.Request.MultipartForm.File {
				for _, fileHeader := range fileHeaders {
					file, err := fileHeader.Open()
					if err == nil {
						// è·å–æ–‡ä»¶çš„MIMEç±»å‹
						mimeType := fileHeader.Header.Get("Content-Type")
						if mimeType == "" || mimeType == "application/octet-stream" {
							ext := strings.ToLower(filepath.Ext(fileHeader.Filename))
							switch ext {
							case ".png":
								mimeType = "image/png"
							case ".jpg", ".jpeg":
								mimeType = "image/jpeg"
							case ".webp":
								mimeType = "image/webp"
							default:
								// å¦‚æœæ— æ³•ç¡®å®šï¼Œé»˜è®¤ä½¿ç”¨image/png
								if key == "image" {
									mimeType = "image/png"
								}
							}
						}

						// ä½¿ç”¨è‡ªå®šä¹‰å¤´éƒ¨åˆ›å»ºè¡¨å•éƒ¨åˆ†
						h := textproto.MIMEHeader{}
						h.Set("Content-Disposition",
							fmt.Sprintf(`form-data; name="%s"; filename="%s"`,
								escapeQuotes(key), escapeQuotes(fileHeader.Filename)))
						h.Set("Content-Type", mimeType)

						// ä½¿ç”¨CreatePartè€Œä¸æ˜¯CreateFormFile
						part, err := writer.CreatePart(h)
						if err == nil {
							io.Copy(part, file)
							logger.Debugf(ctx, "Added file %s with MIME type %s to form", fileHeader.Filename, mimeType)
						} else {
							logger.Errorf(ctx, "Failed to create form part for file %s: %v", fileHeader.Filename, err)
						}
						file.Close()
					} else {
						logger.Errorf(ctx, "Failed to open file %s: %v", fileHeader.Filename, err)
					}
				}
			}

			writer.Close()
			requestBody = body

			// åˆ›å»ºè¯·æ±‚
			req, err = http.NewRequest(c.Request.Method, fullRequestURL, requestBody)
			if err != nil {
				return openai.ErrorWrapper(err, "new_request_failed", http.StatusInternalServerError)
			}

			// è®¾ç½®Content-Typeä¸ºmultipart/form-data
			// æ³¨æ„ï¼šä¸æ‰‹åŠ¨è®¾ç½®Content-Lengthï¼Œè®©Goçš„http.Clientè‡ªåŠ¨è®¡ç®—
			req.Header.Set("Content-Type", writer.FormDataContentType())
			// è®°å½•å®é™…bodyå¤§å°ç”¨äºè°ƒè¯•ï¼Œä½†ä¸è®¾ç½®header
			logger.Debugf(ctx, "Multipart form body size: %d bytes", body.Len())

		} else if strings.Contains(contentType, "application/x-www-form-urlencoded") {
			// è§£æè¡¨å•
			if err := c.Request.ParseForm(); err != nil {
				return openai.ErrorWrapper(err, "parse_form_failed", http.StatusBadRequest)
			}

			// åˆ›å»ºæ–°çš„è¡¨å•æ•°æ®
			formData := url.Values{}

			// æ£€æŸ¥æ˜¯å¦æ˜¯ Gemini æ¨¡å‹
			isGemini := strings.HasPrefix(imageRequest.Model, "gemini")

			for key, values := range c.Request.Form {
				// å¦‚æœæ¨¡å‹è¢«æ˜ å°„ï¼Œåˆ™æ›´æ–°modelå­—æ®µ
				if key == "model" && isModelMapped {
					formData.Set(key, imageRequest.Model)
				} else if isGemini && key == "response_format" {
					// Gemini ä¸æ”¯æŒ response_format å‚æ•°ï¼Œè·³è¿‡è¯¥å‚æ•°
					logger.Debugf(ctx, "Skipping response_format parameter for Gemini model (value: %v)", values)
					continue
				} else {
					for _, value := range values {
						formData.Add(key, value)
					}
				}
			}

			// ç¼–ç è¡¨å•æ•°æ®
			encodedFormData := formData.Encode()
			requestBody = strings.NewReader(encodedFormData)

			// åˆ›å»ºè¯·æ±‚
			req, err = http.NewRequest(c.Request.Method, fullRequestURL, requestBody)
			if err != nil {
				return openai.ErrorWrapper(err, "new_request_failed", http.StatusInternalServerError)
			}

			// è®¾ç½®Content-Type
			// æ³¨æ„ï¼šä¸æ‰‹åŠ¨è®¾ç½®Content-Lengthï¼Œè®©Goçš„http.Clientè‡ªåŠ¨è®¡ç®—
			req.Header.Set("Content-Type", "application/x-www-form-urlencoded")
			// è®°å½•å®é™…æ•°æ®å¤§å°ç”¨äºè°ƒè¯•ï¼Œä½†ä¸è®¾ç½®header
			logger.Debugf(ctx, "Form urlencoded data size: %d bytes", len(encodedFormData))
		}
	} else {
		// å¯¹äºéè¡¨å•è¯·æ±‚ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
		if isModelMapped || meta.ChannelType == common.ChannelTypeAzure {
			jsonStr, err := json.Marshal(imageRequest)
			if err != nil {
				return openai.ErrorWrapper(err, "marshal_image_request_failed", http.StatusInternalServerError)
			}
			requestBody = bytes.NewBuffer(jsonStr)
		} else {
			requestBody = c.Request.Body
		}

		if strings.HasPrefix(imageRequest.Model, "gemini") {
			// åªè¯»å–ä¸€æ¬¡è¯·æ±‚ä½“ï¼Œé¿å…åŒé‡è¯»å–å¯¼è‡´Content-Lengthé”™è¯¯
			bodyBytes, err := io.ReadAll(c.Request.Body)
			if err != nil {
				return openai.ErrorWrapper(err, "read_request_body_failed", http.StatusBadRequest)
			}

			// æ¢å¤è¯·æ±‚ä½“ä»¥ä¾›åç»­ä½¿ç”¨
			c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

			// è§£æè¯·æ±‚ä½“åˆ°map
			var requestMap map[string]interface{}
			if err := json.Unmarshal(bodyBytes, &requestMap); err != nil {
				return openai.ErrorWrapper(fmt.Errorf("è¯·æ±‚ä¸­çš„ JSON æ— æ•ˆ: %w", err), "invalid_request_json", http.StatusBadRequest)
			}

			// Create Gemini image request structure
			geminiImageRequest := gemini.ChatRequest{
				Contents: []gemini.ChatContent{
					{
						Role: "user",
						Parts: []gemini.Part{
							{
								Text: imageRequest.Prompt,
							},
						},
					},
				},
				GenerationConfig: gemini.ChatGenerationConfig{
					ResponseModalities: []string{"Image"},
				},
			}

			// å¤„ç† size å‚æ•°ï¼Œè½¬æ¢ä¸º Gemini çš„ aspectRatio
			if sizeValue, exists := requestMap["size"]; exists {
				if sizeStr, ok := sizeValue.(string); ok && sizeStr != "" {
					aspectRatio := convertSizeToAspectRatio(sizeStr)
					if aspectRatio != "" {
						// åªæœ‰æˆåŠŸè½¬æ¢æ‰è®¾ç½® ImageConfig
						geminiImageRequest.GenerationConfig.ImageConfig = &gemini.ImageConfig{
							AspectRatio: aspectRatio,
						}
						logger.Infof(ctx, "Gemini JSON request: converted size '%s' to aspectRatio '%s'", sizeStr, aspectRatio)
					} else {
						// æ— æ³•è¯†åˆ«çš„æ ¼å¼ï¼Œä¸è®¾ç½® ImageConfigï¼Œä½¿ç”¨ Gemini é»˜è®¤è¡Œä¸º
						logger.Infof(ctx, "Gemini JSON request: unrecognized size format '%s', using Gemini default behavior", sizeStr)
					}
				}
			}

			// å¤„ç†å›¾ç‰‡æ•°æ®ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
			// 1. "image": "å•ä¸ªURLæˆ–base64"
			// 2. "image": ["å¤šä¸ªURL", "å¤šä¸ªbase64", ...]
			// 3. "images": "å•ä¸ªURLæˆ–base64"
			// 4. "images": ["å¤šä¸ªURL", "å¤šä¸ªbase64", ...]

			var imageInputs []string

			// æ£€æŸ¥ "image" å­—æ®µ
			if imageValue, exists := requestMap["image"]; exists {
				imageInputsFromImage := extractImageInputs(imageValue)
				imageInputs = append(imageInputs, imageInputsFromImage...)
				logger.Debugf(ctx, "Found %d image(s) from 'image' field", len(imageInputsFromImage))
			}

			// æ£€æŸ¥ "images" å­—æ®µ
			if imagesValue, exists := requestMap["images"]; exists {
				imageInputsFromImages := extractImageInputs(imagesValue)
				imageInputs = append(imageInputs, imageInputsFromImages...)
				logger.Debugf(ctx, "Found %d image(s) from 'images' field", len(imageInputsFromImages))
			}

			logger.Infof(ctx, "Processing %d total image(s) for Gemini request", len(imageInputs))

			// å¹¶å‘å¤„ç†æ‰€æœ‰æ‰¾åˆ°çš„å›¾ç‰‡
			imageParts, processedCount := processImagesConcurrently(ctx, imageInputs)

			// å°†æˆåŠŸå¤„ç†çš„å›¾ç‰‡æ·»åŠ åˆ°Geminiè¯·æ±‚ä¸­
			geminiImageRequest.Contents[0].Parts = append(geminiImageRequest.Contents[0].Parts, imageParts...)

			logger.Infof(ctx, "Successfully processed %d out of %d images for Gemini request", processedCount, len(imageInputs))

			// Convert to JSON
			jsonStr, err := json.Marshal(geminiImageRequest)
			if err != nil {
				return openai.ErrorWrapper(err, "marshal_gemini_request_failed", http.StatusInternalServerError)
			}

			requestBody = bytes.NewBuffer(jsonStr)

			// Update URL for Gemini API
			if meta.ChannelType == common.ChannelTypeVertexAI {
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] å¼€å§‹å¤„ç†VertexAIå›¾åƒè¯·æ±‚")
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] ChannelId: %d, ChannelType: %d", meta.ChannelId, meta.ChannelType)
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] IsMultiKey: %v, KeyIndex: %v", meta.IsMultiKey, meta.KeyIndex)

				// ä¸ºVertexAIæ„å»ºURL
				keyIndex := 0
				if meta.KeyIndex != nil {
					keyIndex = *meta.KeyIndex
					logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] ä½¿ç”¨KeyIndex: %d", keyIndex)
				}

				// å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿keyIndexä¸ä¸ºè´Ÿæ•°
				if keyIndex < 0 {
					logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] keyIndexä¸ºè´Ÿæ•°: %dï¼Œé‡ç½®ä¸º0", keyIndex)
					keyIndex = 0
				}

				projectID := ""

				// å°è¯•ä»Keyå­—æ®µè§£æé¡¹ç›®IDï¼ˆæ”¯æŒå¤šå¯†é’¥ï¼‰
				if meta.IsMultiKey && len(meta.Keys) > keyIndex && keyIndex >= 0 {
					logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] å¤šå¯†é’¥æ¨¡å¼ï¼ŒKeysæ€»æ•°: %d, å½“å‰ç´¢å¼•: %d", len(meta.Keys), keyIndex)
					// å¤šå¯†é’¥æ¨¡å¼ï¼šä»æŒ‡å®šç´¢å¼•çš„å¯†é’¥è§£æ
					var credentials vertexai.Credentials
					if err := json.Unmarshal([]byte(meta.Keys[keyIndex]), &credentials); err == nil {
						projectID = credentials.ProjectID
						logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] ä»å¤šå¯†é’¥è§£æProjectIDæˆåŠŸ: %s", projectID)
					} else {
						logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] ä»å¤šå¯†é’¥è§£æProjectIDå¤±è´¥: %v", err)
					}
				} else if meta.ActualAPIKey != "" {
					logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] å•å¯†é’¥æ¨¡å¼ï¼ŒActualAPIKeyé•¿åº¦: %d", len(meta.ActualAPIKey))
					// å•å¯†é’¥æ¨¡å¼ï¼šä»ActualAPIKeyè§£æ
					var credentials vertexai.Credentials
					if err := json.Unmarshal([]byte(meta.ActualAPIKey), &credentials); err == nil {
						projectID = credentials.ProjectID
						logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] ä»ActualAPIKeyè§£æProjectIDæˆåŠŸ: %s", projectID)
					} else {
						logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] ä»ActualAPIKeyè§£æProjectIDå¤±è´¥: %v", err)
					}
				} else {
					logger.Warnf(ctx, "ğŸ”§ [VertexAI Debug] æ— æ³•è·å–å¯†é’¥ä¿¡æ¯ï¼ŒIsMultiKey: %v, Keysé•¿åº¦: %d, ActualAPIKeyæ˜¯å¦ä¸ºç©º: %v",
						meta.IsMultiKey, len(meta.Keys), meta.ActualAPIKey == "")
				}

				// å›é€€ï¼šå°è¯•ä»Configè·å–é¡¹ç›®ID
				if projectID == "" && meta.Config.VertexAIProjectID != "" {
					projectID = meta.Config.VertexAIProjectID
					logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] ä»Configè·å–ProjectID: %s", projectID)
				}

				if projectID == "" {
					logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] æ— æ³•è·å–ProjectIDï¼Œæ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥äº†")
					return openai.ErrorWrapper(fmt.Errorf("VertexAI project ID not found"), "vertex_ai_project_id_missing", http.StatusBadRequest)
				}

				region := meta.Config.Region
				if region == "" {
					region = "global"
				}
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] ä½¿ç”¨Region: %s", region)
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] ä½¿ç”¨Model: %s", meta.OriginModelName)

				// æ„å»ºVertexAI API URL - ä½¿ç”¨generateContentè€Œä¸æ˜¯predictç”¨äºå›¾åƒç”Ÿæˆ
				if region == "global" {
					fullRequestURL = fmt.Sprintf("https://aiplatform.googleapis.com/v1/projects/%s/locations/global/publishers/google/models/%s:generateContent", projectID, meta.OriginModelName)
				} else {
					fullRequestURL = fmt.Sprintf("https://%s-aiplatform.googleapis.com/v1/projects/%s/locations/%s/publishers/google/models/%s:generateContent", region, projectID, region, meta.OriginModelName)
				}
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] æ„å»ºçš„å®Œæ•´URL: %s", fullRequestURL)
			} else {
				// åŸæœ‰çš„Geminiå®˜æ–¹API URL
				fullRequestURL = fmt.Sprintf("%s/v1beta/models/%s:generateContent", meta.BaseURL, meta.OriginModelName)
				logger.Infof(ctx, "Gemini API URL: %s", fullRequestURL)
			}
		}

		if meta.ChannelType == 27 {
			// å°†è¯·æ±‚ä½“è§£æä¸º map
			var requestMap map[string]interface{}
			if err := json.NewDecoder(c.Request.Body).Decode(&requestMap); err != nil {
				return openai.ErrorWrapper(err, "decode_request_failed", http.StatusBadRequest)
			}

			// å¦‚æœå­˜åœ¨ size å‚æ•°ï¼Œå°†å…¶å€¼èµ‹ç»™ AspectRatio å¹¶åˆ é™¤ size
			if size, ok := requestMap["size"].(string); ok {
				// å¤„ç†ä¸åŒæ ¼å¼çš„ size
				if strings.Contains(size, "x") {
					// å¤„ç†åˆ†è¾¨ç‡æ ¼å¼ (å¦‚ "1024x1024")
					parts := strings.Split(size, "x")
					if len(parts) == 2 {
						width, wErr := strconv.Atoi(parts[0])
						height, hErr := strconv.Atoi(parts[1])
						if wErr == nil && hErr == nil && width > 0 && height > 0 {
							// è®¡ç®—å®½é«˜æ¯”å¹¶ç®€åŒ–
							gcd := gcd(width, height)
							aspectRatio := fmt.Sprintf("%d:%d", width/gcd, height/gcd)
							requestMap["aspect_ratio"] = aspectRatio
						} else {
							// å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å€¼
							requestMap["aspect_ratio"] = size
						}
					} else {
						requestMap["aspect_ratio"] = size
					}
				} else {
					// ç›´æ¥ä½¿ç”¨æ¯”ä¾‹æ ¼å¼ (å¦‚ "1:1", "4:3")
					requestMap["aspect_ratio"] = size
				}
				delete(requestMap, "size")
			}

			// é‡æ–°åºåˆ—åŒ–
			jsonStr, err := json.Marshal(requestMap)
			if err != nil {
				return openai.ErrorWrapper(err, "marshal_request_failed", http.StatusInternalServerError)
			}

			requestBody = bytes.NewBuffer(jsonStr)
		} else if meta.ChannelType == common.ChannelTypeRecraft {
			// å°†è¯·æ±‚ä½“è§£æä¸º map
			var requestMap map[string]interface{}
			if err := json.NewDecoder(c.Request.Body).Decode(&requestMap); err != nil {
				return openai.ErrorWrapper(err, "decode_request_failed", http.StatusBadRequest)
			}

			// æ£€æŸ¥ model å­—æ®µ
			if model, ok := requestMap["model"].(string); ok {
				if model == "recraftv2" {
					imageRequest.Model = "recraftv2"
					meta.ActualModelName = "recraftv2"
				} else {
					// é»˜è®¤è®¾ç½®ä¸º recraftv3
					imageRequest.Model = "recraftv3"
					meta.ActualModelName = "recraftv3"
				}
			} else {
				// å¦‚æœæ²¡æœ‰ model å­—æ®µï¼Œé»˜è®¤è®¾ç½®ä¸º recraftv3
				imageRequest.Model = "recraftv3"
				meta.ActualModelName = "recraftv3"
			}

			// é‡æ–°åºåˆ—åŒ–
			jsonStr, err := json.Marshal(requestMap)
			if err != nil {
				return openai.ErrorWrapper(err, "marshal_request_failed", http.StatusInternalServerError)
			}
			requestBody = bytes.NewBuffer(jsonStr)
		}

		// åˆ›å»ºè¯·æ±‚
		req, err = http.NewRequest(c.Request.Method, fullRequestURL, requestBody)
		if err != nil {
			return openai.ErrorWrapper(err, "new_request_failed", http.StatusInternalServerError)
		}

		// è®¾ç½®Content-Type
		// æ³¨æ„ï¼šä¸æ‰‹åŠ¨è®¾ç½®Content-Lengthï¼Œè®©Goçš„http.Clientè‡ªåŠ¨è®¡ç®—
		req.Header.Set("Content-Type", contentType)

		// è®°å½•JSONè¯·æ±‚ä½“å¤§å°ç”¨äºè°ƒè¯•ï¼Œä½†ä¸è®¾ç½®header
		if strings.Contains(contentType, "application/json") {
			if bodyBuffer, ok := requestBody.(*bytes.Buffer); ok {
				logger.Debugf(ctx, "JSON request body size: %d bytes", bodyBuffer.Len())
			}
		}
	}

	// åœ¨å‘é€è¯·æ±‚å‰è®°å½•è¯¦ç»†ä¿¡æ¯
	logger.Infof(ctx, "Sending request to %s", fullRequestURL)
	logger.Infof(ctx, "Request Content-Type: %s", req.Header.Get("Content-Type"))
	// Content-Lengthç°åœ¨ç”±Goçš„http.Clientè‡ªåŠ¨è®¡ç®—ï¼Œä¸éœ€è¦æ‰‹åŠ¨éªŒè¯
	logger.Debugf(ctx, "HTTP client will auto-calculate Content-Length")

	// VertexAIè°ƒè¯•ä¿¡æ¯
	if meta.ChannelType == common.ChannelTypeVertexAI && strings.HasPrefix(imageRequest.Model, "gemini") {
		logger.Infof(ctx, "ğŸ“¤ [VertexAI Debug] å³å°†å‘é€è¯·æ±‚åˆ°VertexAI")
		logger.Infof(ctx, "ğŸ“¤ [VertexAI Debug] Request Headers: Content-Type=%s, Authorization=%s",
			req.Header.Get("Content-Type"),
			func() string {
				auth := req.Header.Get("Authorization")
				if len(auth) > 20 {
					return auth[:20] + "..."
				}
				return auth
			}())
	}

	// å¦‚æœæ˜¯è¡¨å•è¯·æ±‚ï¼Œè®°å½•è¡¨å•å†…å®¹
	if isFormRequest && strings.Contains(contentType, "multipart/form-data") {
		for key, values := range c.Request.MultipartForm.Value {
			logger.Debugf(ctx, "Form field: %s = %s", key, values[0])
		}

		for key, fileHeaders := range c.Request.MultipartForm.File {
			for _, fileHeader := range fileHeaders {
				logger.Debugf(ctx, "Form file: %s, filename: %s, size: %d, content-type: %s",
					key, fileHeader.Filename, fileHeader.Size, fileHeader.Header.Get("Content-Type"))
			}
		}
	}

	adaptor := helper.GetAdaptor(meta.APIType)
	if adaptor == nil {
		return openai.ErrorWrapper(fmt.Errorf("invalid api typezz: %d", meta.APIType), "invalid_api_type", http.StatusBadRequest)
	}
	adaptor.Init(meta)
	groupRatio := common.GetGroupRatio(meta.Group)
	// userModelTypeRatio := common.GetUserModelTypeRation(meta.Group, imageRequest.Model)
	ratio := groupRatio
	userQuota, err := model.CacheGetUserQuota(ctx, meta.UserId)
	if err != nil {
		return openai.ErrorWrapper(err, "failed to get user quota", http.StatusInternalServerError)
	}

	modelPrice := common.GetModelPrice(imageRequest.Model, false)
	if modelPrice == -1 {
		modelPrice = 0.1 // é»˜è®¤ä»·æ ¼
	}
	quota := int64(modelPrice*500000*imageCostRatio*ratio) * int64(imageRequest.N)

	if userQuota-quota < 0 {
		return openai.ErrorWrapper(errors.New("user quota is not enough"), "insufficient_user_quota", http.StatusForbidden)
	}

	// è®¾ç½®é€šç”¨è¯·æ±‚å¤´
	token := c.Request.Header.Get("Authorization")
	if meta.ChannelType == common.ChannelTypeAzure {
		token = strings.TrimPrefix(token, "Bearer ")
		req.Header.Set("api-key", token)
	} else if strings.HasPrefix(imageRequest.Model, "gemini") {
		if meta.ChannelType == common.ChannelTypeVertexAI {
			logger.Infof(ctx, "ğŸ” [VertexAI Debug] å¼€å§‹VertexAIè®¤è¯æµç¨‹")
			// ä¸ºVertexAIä½¿ç”¨Bearer tokenè®¤è¯ - å¤ç”¨å·²æœ‰çš„adaptorå®ä¾‹
			var vertexAIAdaptor *vertexai.Adaptor
			if va, ok := adaptor.(*vertexai.Adaptor); ok {
				vertexAIAdaptor = va
			} else {
				// å¦‚æœä¸æ˜¯VertexAIé€‚é…å™¨ï¼Œåˆ›å»ºæ–°å®ä¾‹ï¼ˆè¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿï¼‰
				vertexAIAdaptor = &vertexai.Adaptor{}
				vertexAIAdaptor.Init(meta)
				logger.Warnf(ctx, "ğŸ” [VertexAI Debug] è­¦å‘Šï¼šadaptorç±»å‹ä¸åŒ¹é…ï¼Œåˆ›å»ºæ–°çš„VertexAIé€‚é…å™¨å®ä¾‹")
			}

			logger.Infof(ctx, "ğŸ” [VertexAI Debug] è°ƒç”¨GetAccessTokenè·å–è®¿é—®ä»¤ç‰Œ")
			accessToken, err := vertexai.GetAccessToken(vertexAIAdaptor, meta)
			if err != nil {
				logger.Errorf(ctx, "ğŸ” [VertexAI Debug] è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: %v", err)
				return openai.ErrorWrapper(fmt.Errorf("failed to get VertexAI access token: %v", err), "vertex_ai_auth_failed", http.StatusUnauthorized)
			}

			// åªæ˜¾ç¤ºä»¤ç‰Œçš„å‰10ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•ï¼Œé¿å…å®Œæ•´ä»¤ç‰Œæ³„éœ²
			tokenPreview := ""
			if len(accessToken) > 10 {
				tokenPreview = accessToken[:10] + "..."
			} else {
				tokenPreview = accessToken
			}
			logger.Infof(ctx, "ğŸ” [VertexAI Debug] æˆåŠŸè·å–è®¿é—®ä»¤ç‰Œï¼Œé•¿åº¦: %d, å‰ç¼€: %s", len(accessToken), tokenPreview)

			req.Header.Set("Authorization", "Bearer "+accessToken)
			logger.Infof(ctx, "ğŸ” [VertexAI Debug] å·²è®¾ç½®Authorization headerä¸ºBearer token")
		} else {
			// For Gemini, set the API key in the x-goog-api-key header
			req.Header.Set("x-goog-api-key", meta.APIKey)
			logger.Infof(ctx, "Setting x-goog-api-key header for Gemini API request")
		}
	} else {
		req.Header.Set("Authorization", token)
	}

	req.Header.Set("Accept", c.Request.Header.Get("Accept"))

	resp, err := util.HTTPClient.Do(req)
	if err != nil {
		return openai.ErrorWrapper(err, "do_request_failed", http.StatusInternalServerError)
	}

	// deferå…³é—­è¯·æ±‚ä½“ï¼Œç¡®ä¿åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½ä¼šè¢«å…³é—­
	defer func() {
		if req.Body != nil {
			if err := req.Body.Close(); err != nil {
				logger.Warnf(ctx, "å…³é—­è¯·æ±‚ä½“å¤±è´¥: %v", err)
			}
		}
		if c.Request.Body != nil {
			if err := c.Request.Body.Close(); err != nil {
				logger.Warnf(ctx, "å…³é—­åŸå§‹è¯·æ±‚ä½“å¤±è´¥: %v", err)
			}
		}
	}()
	var imageResponse openai.ImageResponse
	var responseBody []byte

	// ç”¨äºä¿å­˜ Gemini token ä¿¡æ¯
	var geminiPromptTokens, geminiCompletionTokens int

	// å®šä¹‰ token å˜é‡ä¾› defer å‡½æ•°ä½¿ç”¨
	var promptTokens, completionTokens int

	defer func(ctx context.Context) {
		if resp == nil || (resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated) {
			return
		}

		// å¯¹äº gpt-image-1 å’Œ gpt-image-1-mini æ¨¡å‹ï¼Œå…ˆè§£æå“åº”å¹¶è®¡ç®— quota
		if meta.ActualModelName == "gpt-image-1" || meta.ActualModelName == "gpt-image-1-mini" {
			var parsedResponse openai.ImageResponse
			if err := json.Unmarshal(responseBody, &parsedResponse); err != nil {
				logger.SysError("error parsing gpt-image-1 response: " + err.Error())
			} else {
				// å…ˆå°†ä»¤ç‰Œæ•°è½¬æ¢ä¸ºæµ®ç‚¹æ•°
				textTokens := float64(parsedResponse.Usage.InputTokensDetails.TextTokens)
				imageTokens := float64(parsedResponse.Usage.InputTokensDetails.ImageTokens)
				outputTokens := float64(parsedResponse.Usage.OutputTokens)

				// ä¿å­˜æ—§çš„ quota å€¼ç”¨äºæ—¥å¿—
				oldQuota := quota

				// ä½¿ç”¨ç°æœ‰çš„ModelRatioå’ŒCompletionRatioæœºåˆ¶è¿›è¡Œè®¡è´¹
				modelRatio := common.GetModelRatio(meta.ActualModelName)
				completionRatio := common.GetCompletionRatio(meta.ActualModelName)
				groupRatio := common.GetGroupRatio(meta.Group)

				// æ ¹æ®ä¸åŒæ¨¡å‹è®¾ç½®ä¸åŒçš„image tokensä»·æ ¼å€ç‡
				var imageTokenMultiplier float64
				if meta.ActualModelName == "gpt-image-1-mini" {
					// gpt-image-1-mini çš„ image tokens ä»·æ ¼æ˜¯æ–‡æœ¬çš„1.25å€
					imageTokenMultiplier = 1.25
				} else {
					// gpt-image-1 çš„ image tokens ä»·æ ¼æ˜¯æ–‡æœ¬çš„2å€
					imageTokenMultiplier = 2.0
				}

				// è®¡ç®—è¾“å…¥tokensï¼šæ–‡æœ¬tokens + å›¾ç‰‡tokens * ç›¸åº”å€ç‡
				inputTokensEquivalent := textTokens + imageTokens*imageTokenMultiplier

				// ä½¿ç”¨æ ‡å‡†çš„è®¡è´¹å…¬å¼ï¼š(è¾“å…¥tokens + è¾“å‡ºtokens * å®Œæˆæ¯”ç‡) * æ¨¡å‹æ¯”ç‡ * åˆ†ç»„æ¯”ç‡
				// æ³¨æ„ï¼šä»·æ ¼æ˜¯1000tokensçš„å•ä»·ï¼Œéœ€è¦é™¤ä»¥1000ï¼Œç„¶åä¹˜ä»¥500000å¾—åˆ°çœŸæ­£çš„æ‰£è´¹quota
				calculatedQuota := int64(math.Ceil((inputTokensEquivalent + outputTokens*completionRatio) * modelRatio * groupRatio))
				quota = calculatedQuota

				// è®°å½•æ—¥å¿—
				logger.Infof(ctx, "%s token usage: text=%d, image=%d (multiplier=%.2f), output=%d, old quota=%d, new quota=%d",
					meta.ActualModelName, int(textTokens), int(imageTokens), imageTokenMultiplier, int(outputTokens), oldQuota, quota)

				// æ›´æ–° defer å‡½æ•°ä¸­çš„ token å˜é‡ï¼Œä»¥ä¾¿æ­£ç¡®è®°å½•åˆ°æ—¥å¿—è¡¨ä¸­
				// promptTokens è®°å½•çš„æ˜¯ç­‰æ•ˆçš„è¾“å…¥ tokensï¼ˆæ–‡æœ¬ + å›¾ç‰‡æŒ‰æ¯”ä¾‹æ¢ç®—ï¼‰
				// ä½¿ç”¨å‘ä¸Šå–æ•´ç¡®ä¿å°æ•°éƒ¨åˆ†ä¸ä¼šä¸¢å¤±
				promptTokens = int(math.Ceil(inputTokensEquivalent))
				completionTokens = int(outputTokens)
			}
		}

		// å¯¹äºè±†åŒ…å›¾ç‰‡æ¨¡å‹ï¼ŒæŒ‰æ¬¡è®¡è´¹ï¼ˆä¸å†ä½¿ç”¨tokenè®¡è´¹ï¼‰
		if meta.ChannelType == 40 {
			// åªè§£æusageä¿¡æ¯è·å–ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
			var usageInfo struct {
				Model string `json:"model,omitempty"`
				Usage struct {
					GeneratedImages int `json:"generated_images,omitempty"`
					OutputTokens    int `json:"output_tokens,omitempty"`
					TotalTokens     int `json:"total_tokens,omitempty"`
				} `json:"usage,omitempty"`
			}

			if err := json.Unmarshal(responseBody, &usageInfo); err != nil {
				logger.SysError("error parsing doubao image usage: " + err.Error())
			} else {
				// ä¿å­˜æ—§çš„ quota å€¼ç”¨äºæ—¥å¿—
				oldQuota := quota

				// ä½¿ç”¨æŒ‰æ¬¡è®¡è´¹ï¼šä»ç”¨æˆ·å¯é…ç½®çš„ ModelPrice è·å–å•ä»·
				modelPrice := common.GetModelPrice(meta.ActualModelName, false)
				if modelPrice == -1 {
					modelPrice = 0.3 // é»˜è®¤ä»·æ ¼ 0.3 ç¾é‡‘
				}

				groupRatio := common.GetGroupRatio(meta.Group)
				generatedImages := usageInfo.Usage.GeneratedImages
				if generatedImages <= 0 {
					generatedImages = 1 // è‡³å°‘ç”Ÿæˆ1å¼ å›¾ç‰‡
				}

				// æŒ‰æ¬¡è®¡è´¹ï¼šå•ä»· * ç”Ÿæˆå›¾ç‰‡æ•° * åˆ†ç»„å€ç‡ * 500000ï¼ˆè½¬æ¢ä¸ºé…é¢ï¼‰
				calculatedQuota := int64(modelPrice * float64(generatedImages) * groupRatio * 500000)
				quota = calculatedQuota

				// è®°å½•æ—¥å¿—
				logger.Infof(ctx, "Doubao Image per-call pricing: generated_images=%d, price=$%.2f, old quota=%d, new quota=%d",
					generatedImages, modelPrice, oldQuota, quota)

				// å¤„ç†é…é¢æ¶ˆè´¹å’Œæ—¥å¿—è®°å½•
				err := model.PostConsumeTokenQuota(meta.TokenId, quota)
				if err != nil {
					logger.SysError("error consuming token remain quota for doubao image: " + err.Error())
				}

				err = model.CacheUpdateUserQuota(ctx, meta.UserId)
				if err != nil {
					logger.SysError("error update user quota cache for doubao image: " + err.Error())
				}

				referer := c.Request.Header.Get("HTTP-Referer")
				title := c.Request.Header.Get("X-Title")
				rowDuration := time.Since(startTime).Seconds()
				duration := math.Round(rowDuration*1000) / 1000
				tokenName := c.GetString("token_name")
				xRequestID := c.GetString("X-Request-ID")

				// è·å–æ¨¡å‹åï¼Œå¦‚æœè§£æä¸åˆ°å°±ä½¿ç”¨metaä¸­çš„
				modelName := usageInfo.Model
				if modelName == "" {
					modelName = meta.ActualModelName
				}

				// è®¡ç®—è¯¦ç»†çš„æˆæœ¬ä¿¡æ¯
				totalCost := float64(quota) / 500000
				logContent := fmt.Sprintf("Doubao Image Request - Model: %s, Generated images: %d, Price per image: $%.2f, Total cost: $%.6f, Duration: %.3fs",
					modelName, generatedImages, modelPrice, totalCost, duration)

				// è·å–æ¸ é“å†å²ä¿¡æ¯å¹¶è®°å½•æ—¥å¿—
				var otherInfo string
				if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
					if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
						if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
							otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
						}
					}
				}

				if otherInfo != "" {
					model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, 0, generatedImages, modelName, tokenName, quota, logContent, duration, title, referer, false, 0.0, otherInfo, xRequestID)
				} else {
					model.RecordConsumeLogWithRequestID(ctx, meta.UserId, meta.ChannelId, 0, generatedImages, modelName, tokenName, quota, logContent, duration, title, referer, false, 0.0, xRequestID)
				}
				model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, quota)
				channelId := c.GetInt("channel_id")
				model.UpdateChannelUsedQuota(channelId, quota)

				// æ›´æ–°å¤šKeyä½¿ç”¨ç»Ÿè®¡
				UpdateMultiKeyUsageFromContext(c, quota > 0)

				logger.Infof(ctx, "Doubao Image per-call consumption completed: generated_images=%d, quota=%d, duration=%.3fs",
					generatedImages, quota, duration)
				return // è·³è¿‡åç»­å¤„ç†
			}
		}

		// å¯¹äº Gemini æ¨¡å‹ï¼Œè·³è¿‡å¤„ç†ï¼ˆå·²åœ¨å“åº”å¤„ç†ä¸­ç›´æ¥å¤„ç†ï¼‰
		if strings.HasPrefix(meta.ActualModelName, "gemini") || strings.HasPrefix(meta.OriginModelName, "gemini") {
			logger.Infof(ctx, "Defer å‡½æ•°è·³è¿‡ Gemini æ¨¡å‹å¤„ç†ï¼ˆå·²åœ¨å“åº”å¤„ç†ä¸­å®Œæˆï¼‰: ActualModelName=%s, OriginModelName=%s", meta.ActualModelName, meta.OriginModelName)
			return // è·³è¿‡ Gemini çš„å¤„ç†
		}

		// ç„¶åå†å¤„ç†é…é¢æ¶ˆè´¹
		err := model.PostConsumeTokenQuota(meta.TokenId, quota)
		if err != nil {
			logger.SysError("error consuming token remain quota: " + err.Error())
		}

		err = model.CacheUpdateUserQuota(ctx, meta.UserId)
		if err != nil {
			logger.SysError("error update user quota cache: " + err.Error())
		}

		referer := c.Request.Header.Get("HTTP-Referer")
		title := c.Request.Header.Get("X-Title")
		rowDuration := time.Since(startTime).Seconds()
		duration := math.Round(rowDuration*1000) / 1000
		tokenName := c.GetString("token_name")
		xRequestID := c.GetString("X-Request-ID")

		// å¯¹äº Gemini æ¨¡å‹ï¼ŒåŒ…å« token ä½¿ç”¨ä¿¡æ¯
		var logContent string
		if strings.HasPrefix(meta.ActualModelName, "gemini") || strings.HasPrefix(meta.OriginModelName, "gemini") {
			modelPriceFloat := float64(quota) / 500000
			logContent = fmt.Sprintf("Gemini JSON Request - Model: %s, Price: $%.4f, Tokens: prompt=%d, completion=%d, total=%d",
				meta.OriginModelName, modelPriceFloat, promptTokens, completionTokens, promptTokens+completionTokens)
		} else {
			logContent = fmt.Sprintf("æ¨¡å‹ä»·æ ¼ $%.2fï¼Œåˆ†ç»„å€ç‡ %.2f", modelPrice, groupRatio)
		}

		// è®°å½•æ¶ˆè´¹æ—¥å¿— - åœ¨RelayImageHelperä¸­ä¸éœ€è¦å¤„ç†otherå­—æ®µï¼Œè¿™ç”±å…·ä½“çš„å¤„ç†å‡½æ•°è´Ÿè´£
		model.RecordConsumeLogWithRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.ActualModelName, tokenName, quota, logContent, duration, title, referer, false, 0.0, xRequestID)
		model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, quota)
		channelId := c.GetInt("channel_id")
		model.UpdateChannelUsedQuota(channelId, quota)

		// æ›´æ–°å¤šKeyä½¿ç”¨ç»Ÿè®¡
		UpdateMultiKeyUsageFromContext(c, quota > 0)

	}(c.Request.Context())

	// âœ… å…³é”®ä¿®å¤ï¼šä½¿ç”¨ defer ç¡®ä¿å“åº”ä½“ä¸€å®šä¼šè¢«å…³é—­
	defer func() {
		if resp != nil && resp.Body != nil {
			_ = resp.Body.Close()
		}
	}()

	responseBody, err = io.ReadAll(resp.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_response_body_failed", http.StatusInternalServerError)
	}

	// æ£€æŸ¥HTTPçŠ¶æ€ç ï¼Œå¦‚æœä¸æ˜¯æˆåŠŸçŠ¶æ€ç ï¼Œç›´æ¥è¿”å›é”™è¯¯
	if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated {
		logger.Errorf(ctx, "APIè¿”å›é”™è¯¯çŠ¶æ€ç : %d, å“åº”ä½“: %s", resp.StatusCode, string(responseBody))

		// æ£€æŸ¥é”™è¯¯è¿”å›æ—¶çš„ä¸Šä¸‹æ–‡çŠ¶æ€
		if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
			logger.Infof(ctx, "RelayImageHelper: EXIT ERROR - admin_channel_history exists: %v", channelHistoryInterface)
		} else {
			logger.Warnf(ctx, "RelayImageHelper: EXIT ERROR - admin_channel_history NOT found")
		}

		logger.Errorf(ctx, "RelayImageHelper EXIT ERROR: returning error for status %d", resp.StatusCode)
		return openai.ErrorWrapper(
			fmt.Errorf("APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : %dï¼Œå“åº”: %s", resp.StatusCode, string(responseBody)),
			"api_error",
			resp.StatusCode,
		)
	}

	// Handle Gemini response format conversion
	if strings.HasPrefix(meta.OriginModelName, "gemini") {
		logger.Infof(ctx, "è¿›å…¥ Gemini å“åº”å¤„ç†é€»è¾‘ï¼ŒåŸå§‹æ¨¡å‹: %s, æ˜ å°„åæ¨¡å‹: %s", meta.OriginModelName, imageRequest.Model)
		// Add debug logging for the original response bodyï¼ˆçœç•¥å…·ä½“å†…å®¹ï¼Œé¿å… base64 æ•°æ®å ç”¨æ—¥å¿—ï¼‰
		logger.Infof(ctx, "Gemini åŸå§‹å“åº”å·²æ¥æ”¶ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)

		// VertexAIç‰¹å®šçš„è°ƒè¯•ä¿¡æ¯
		if meta.ChannelType == common.ChannelTypeVertexAI {
			logger.Infof(ctx, "ğŸ“¥ [VertexAI Debug] æ”¶åˆ°VertexAIå“åº”ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)
			logger.Infof(ctx, "ğŸ“¥ [VertexAI Debug] å“åº”ä½“é•¿åº¦: %d bytes", len(responseBody))

			// æ£€æŸ¥å“åº”å¤´
			if contentType := resp.Header.Get("Content-Type"); contentType != "" {
				logger.Infof(ctx, "ğŸ“¥ [VertexAI Debug] å“åº”Content-Type: %s", contentType)
			}
		}

		logger.Infof(ctx, "å¤„ç† Gemini å“åº”ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)

		// Check if response is an error
		var geminiError struct {
			Error struct {
				Code    int                      `json:"code"`
				Message string                   `json:"message"`
				Status  string                   `json:"status"`
				Details []map[string]interface{} `json:"details,omitempty"`
			} `json:"error"`
		}

		if err := json.Unmarshal(responseBody, &geminiError); err != nil {
			logger.Errorf(ctx, "è§£æ Gemini é”™è¯¯å“åº”å¤±è´¥: %s", err.Error())
			// VertexAIç‰¹å®šçš„é”™è¯¯è§£æè°ƒè¯•
			if meta.ChannelType == common.ChannelTypeVertexAI {
				logger.Errorf(ctx, "ğŸš¨ [VertexAI Debug] VertexAIé”™è¯¯å“åº”è§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”: %s", string(responseBody))
			}
		} else if geminiError.Error.Message != "" {
			if meta.ChannelType == common.ChannelTypeVertexAI {
				logger.Errorf(ctx, "ğŸš¨ [VertexAI Debug] VertexAI API è¿”å›é”™è¯¯: ä»£ç =%d, æ¶ˆæ¯=%s, çŠ¶æ€=%s",
					geminiError.Error.Code,
					geminiError.Error.Message,
					geminiError.Error.Status)
			} else {
				logger.Errorf(ctx, "Gemini API è¿”å›é”™è¯¯: ä»£ç =%d, æ¶ˆæ¯=%s, çŠ¶æ€=%s",
					geminiError.Error.Code,
					geminiError.Error.Message,
					geminiError.Error.Status)
			}

			if len(geminiError.Error.Details) > 0 {
				detailsJson, _ := json.Marshal(geminiError.Error.Details)
				if meta.ChannelType == common.ChannelTypeVertexAI {
					logger.Errorf(ctx, "ğŸš¨ [VertexAI Debug] VertexAIé”™è¯¯è¯¦æƒ…: %s", string(detailsJson))
				} else {
					logger.Errorf(ctx, "é”™è¯¯è¯¦æƒ…: %s", string(detailsJson))
				}
			}

			// Use the existing ErrorWrapper function to handle the error
			var errorMsg error
			if meta.ChannelType == common.ChannelTypeVertexAI {
				errorMsg = fmt.Errorf("VertexAI API é”™è¯¯: %s (çŠ¶æ€: %s)",
					geminiError.Error.Message,
					geminiError.Error.Status)
			} else {
				errorMsg = fmt.Errorf("Gemini API é”™è¯¯: %s (çŠ¶æ€: %s)",
					geminiError.Error.Message,
					geminiError.Error.Status)
			}

			errorCode := "gemini_" + strings.ToLower(geminiError.Error.Status)
			if meta.ChannelType == common.ChannelTypeVertexAI {
				errorCode = "vertex_ai_" + strings.ToLower(geminiError.Error.Status)
			}
			statusCode := geminiError.Error.Code
			if statusCode == 0 {
				statusCode = http.StatusBadRequest
			}

			return openai.ErrorWrapper(errorMsg, errorCode, statusCode)
		}

		var geminiResponse struct {
			Candidates []struct {
				Content struct {
					Parts []struct {
						InlineData *gemini.InlineData `json:"inlineData,omitempty"`
						Text       string             `json:"text,omitempty"`
					} `json:"parts,omitempty"`
					Role string `json:"role,omitempty"`
				} `json:"content,omitempty"`
				FinishReason  string `json:"finishReason,omitempty"`
				FinishMessage string `json:"finishMessage,omitempty"`
				Index         int    `json:"index,omitempty"`
			} `json:"candidates,omitempty"`
			PromptFeedback *struct {
				BlockReason        string `json:"blockReason,omitempty"`
				BlockReasonMessage string `json:"blockReasonMessage,omitempty"`
			} `json:"promptFeedback,omitempty"`
			ModelVersion  string `json:"modelVersion,omitempty"`
			UsageMetadata struct {
				PromptTokenCount     int `json:"promptTokenCount,omitempty"`
				CandidatesTokenCount int `json:"candidatesTokenCount,omitempty"`
				TotalTokenCount      int `json:"totalTokenCount,omitempty"`
			} `json:"usageMetadata,omitempty"`
		}

		err = json.Unmarshal(responseBody, &geminiResponse)
		if err != nil {
			logger.Errorf(ctx, "è§£æ Gemini æˆåŠŸå“åº”å¤±è´¥: %s", err.Error())
			return openai.ErrorWrapper(err, "unmarshal_gemini_response_failed", http.StatusInternalServerError)
		}

		// ä¿å­˜ Gemini token ä¿¡æ¯åˆ°å…¨å±€å˜é‡ï¼Œä¾› defer å‡½æ•°ä½¿ç”¨
		if meta.ChannelType == common.ChannelTypeVertexAI {
			logger.Infof(ctx, "ğŸ“Š [VertexAI Debug] å‡†å¤‡ä¿å­˜ VertexAI token ä¿¡æ¯")
			logger.Infof(ctx, "ğŸ“Š [VertexAI Debug] åŸå§‹ UsageMetadata: PromptTokenCount=%d, CandidatesTokenCount=%d, TotalTokenCount=%d",
				geminiResponse.UsageMetadata.PromptTokenCount,
				geminiResponse.UsageMetadata.CandidatesTokenCount,
				geminiResponse.UsageMetadata.TotalTokenCount)
		} else {
			logger.Infof(ctx, "å‡†å¤‡ä¿å­˜ Gemini token ä¿¡æ¯")
			logger.Infof(ctx, "åŸå§‹ UsageMetadata: PromptTokenCount=%d, CandidatesTokenCount=%d, TotalTokenCount=%d",
				geminiResponse.UsageMetadata.PromptTokenCount,
				geminiResponse.UsageMetadata.CandidatesTokenCount,
				geminiResponse.UsageMetadata.TotalTokenCount)
		}

		geminiPromptTokens = geminiResponse.UsageMetadata.PromptTokenCount
		geminiCompletionTokens = geminiResponse.UsageMetadata.CandidatesTokenCount

		if meta.ChannelType == common.ChannelTypeVertexAI {
			logger.Infof(ctx, "ğŸ“Š [VertexAI Debug] å·²ä¿å­˜ VertexAI token ä¿¡æ¯: geminiPromptTokens=%d, geminiCompletionTokens=%d",
				geminiPromptTokens, geminiCompletionTokens)
			logger.Infof(ctx, "ğŸ“Š [VertexAI Debug] VertexAI JSON token usage: prompt=%d, completion=%d, total=%d",
				geminiPromptTokens, geminiCompletionTokens, geminiResponse.UsageMetadata.TotalTokenCount)
		} else {
			logger.Infof(ctx, "å·²ä¿å­˜ Gemini token ä¿¡æ¯: geminiPromptTokens=%d, geminiCompletionTokens=%d",
				geminiPromptTokens, geminiCompletionTokens)
			logger.Infof(ctx, "Gemini JSON token usage: prompt=%d, completion=%d, total=%d",
				geminiPromptTokens, geminiCompletionTokens, geminiResponse.UsageMetadata.TotalTokenCount)
		}

		// æ£€æŸ¥ promptFeedback æ˜¯å¦æœ‰é˜»æ­¢åŸå› 
		if geminiResponse.PromptFeedback != nil && geminiResponse.PromptFeedback.BlockReason != "" {
			var errorMessage string
			if geminiResponse.PromptFeedback.BlockReasonMessage != "" {
				errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: %s (åŸå› : %s)",
					geminiResponse.PromptFeedback.BlockReasonMessage,
					geminiResponse.PromptFeedback.BlockReason)
			} else {
				errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: æç¤ºè¯è¢«é˜»æ­¢ (åŸå› : %s)",
					geminiResponse.PromptFeedback.BlockReason)
			}

			logger.Errorf(ctx, "Gemini API promptFeedback é˜»æ­¢: BlockReason=%s, Message=%s",
				geminiResponse.PromptFeedback.BlockReason,
				geminiResponse.PromptFeedback.BlockReasonMessage)

			// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•
			responseStr := string(responseBody)
			if len(responseStr) > 1000 {
				responseStr = responseStr[:1000] + "...[truncated]"
			}
			logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

			// æ„å»ºåŒ…å«é”™è¯¯å’Œusageä¿¡æ¯çš„å“åº”
			errorResponse := map[string]interface{}{
				"error": map[string]interface{}{
					"code":    "gemini_prompt_blocked",
					"message": errorMessage,
					"param":   "",
					"type":    "api_error",
				},
				"created": time.Now().Unix(),
				"data":    nil,
				"usage": map[string]interface{}{
					"total_tokens":  geminiResponse.UsageMetadata.TotalTokenCount,
					"input_tokens":  geminiResponse.UsageMetadata.PromptTokenCount,
					"output_tokens": geminiResponse.UsageMetadata.CandidatesTokenCount,
					"input_tokens_details": map[string]int{
						"text_tokens":  0,
						"image_tokens": 0,
					},
				},
			}

			// ç›´æ¥è¿”å›å“åº”
			c.JSON(http.StatusBadRequest, errorResponse)

			// è®¡ç®—è¯·æ±‚è€—æ—¶
			rowDuration := time.Since(startTime).Seconds()
			duration := math.Round(rowDuration*1000) / 1000

			// å¤„ç†é…é¢æ¶ˆè´¹
			groupRatio := common.GetGroupRatio(meta.Group)
			promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
			completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

			modelRatio := common.GetModelRatio(meta.OriginModelName)
			completionRatio := common.GetCompletionRatio(meta.OriginModelName)
			actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

			logger.Infof(ctx, "Gemini JSON promptFeedback é˜»æ­¢å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
				promptTokens, completionTokens, groupRatio, actualQuota, duration)

			// æ¶ˆè´¹é…é¢
			err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
			if err != nil {
				logger.SysError("error consuming token remain quota: " + err.Error())
			}

			err = model.CacheUpdateUserQuota(ctx, meta.UserId)
			if err != nil {
				logger.SysError("error update user quota cache: " + err.Error())
			}

			// è®°å½•æ¶ˆè´¹æ—¥å¿—
			referer := c.Request.Header.Get("HTTP-Referer")
			title := c.Request.Header.Get("X-Title")
			tokenName := c.GetString("token_name")
			xRequestID := c.GetString("X-Request-ID")

			logContent := fmt.Sprintf("Gemini JSON Prompt Blocked - Model: %s, BlockReason: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
				meta.OriginModelName, geminiResponse.PromptFeedback.BlockReason, promptTokens, completionTokens, actualQuota, duration)

			// è·å–æ¸ é“å†å²ä¿¡æ¯
			var otherInfo string
			if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
				if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
					if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
						otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
					}
				}
			}

			// è®°å½•æ—¥å¿—
			model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
				tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

			model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
			channelId := c.GetInt("channel_id")
			model.UpdateChannelUsedQuota(channelId, actualQuota)

			return nil
		}

		// æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰é¡¹
		if len(geminiResponse.Candidates) == 0 {
			logger.Errorf(ctx, "Gemini API æœªè¿”å›ä»»ä½•å€™é€‰é¡¹")
			// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
			responseStr := string(responseBody)
			if len(responseStr) > 1000 {
				responseStr = responseStr[:1000] + "...[truncated]"
			}
			logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

			// è®°å½•æ¶ˆè´¹æ—¥å¿—ï¼ˆå³ä½¿æ²¡æœ‰å€™é€‰é¡¹ï¼Œä¹Ÿè¦è®°å½•è¯·æ±‚æ¶ˆè€—ï¼‰
			rowDuration := time.Since(startTime).Seconds()
			duration := math.Round(rowDuration*1000) / 1000

			groupRatio := common.GetGroupRatio(meta.Group)
			promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
			completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

			modelRatio := common.GetModelRatio(meta.OriginModelName)
			completionRatio := common.GetCompletionRatio(meta.OriginModelName)
			actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

			logger.Infof(ctx, "Gemini JSON ç©ºå€™é€‰é¡¹å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
				promptTokens, completionTokens, groupRatio, actualQuota, duration)

			// æ¶ˆè´¹é…é¢
			err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
			if err != nil {
				logger.SysError("error consuming token remain quota: " + err.Error())
			}

			err = model.CacheUpdateUserQuota(ctx, meta.UserId)
			if err != nil {
				logger.SysError("error update user quota cache: " + err.Error())
			}

			// è®°å½•æ¶ˆè´¹æ—¥å¿—
			referer := c.Request.Header.Get("HTTP-Referer")
			title := c.Request.Header.Get("X-Title")
			tokenName := c.GetString("token_name")
			xRequestID := c.GetString("X-Request-ID")

			logContent := fmt.Sprintf("Gemini JSON No Candidates - Model: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
				meta.OriginModelName, promptTokens, completionTokens, actualQuota, duration)

			// è·å–æ¸ é“å†å²ä¿¡æ¯
			var otherInfo string
			if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
				if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
					if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
						otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
					}
				}
			}

			// è®°å½•æ—¥å¿—
			model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
				tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

			model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
			channelId := c.GetInt("channel_id")
			model.UpdateChannelUsedQuota(channelId, actualQuota)

			return openai.ErrorWrapper(
				fmt.Errorf("Gemini API é”™è¯¯: æœªè¿”å›ä»»ä½•å€™é€‰é¡¹"),
				"gemini_no_candidates",
				http.StatusBadRequest,
			)
		}

		// Check if any candidate has a finish reason that isn't STOP
		for _, candidate := range geminiResponse.Candidates {
			if candidate.FinishReason != "" && candidate.FinishReason != "STOP" {
				// æ„å»ºé”™è¯¯æ¶ˆæ¯ï¼Œä¼˜å…ˆä½¿ç”¨ finishMessage
				var errorMessage string
				if candidate.FinishMessage != "" {
					errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: %s (åŸå› : %s)", candidate.FinishMessage, candidate.FinishReason)
					logger.Errorf(ctx, "Gemini API è¿”å›éæ­£å¸¸å®Œæˆ: FinishReason=%s, FinishMessage=%s", candidate.FinishReason, candidate.FinishMessage)
				} else {
					errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: ç”Ÿæˆæœªæ­£å¸¸å®Œæˆ (åŸå› : %s)", candidate.FinishReason)
					logger.Errorf(ctx, "Gemini API è¿”å›éæ­£å¸¸å®ŒæˆåŸå› : %s", candidate.FinishReason)
				}

				// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
				responseStr := string(responseBody)
				if len(responseStr) > 1000 {
					responseStr = responseStr[:1000] + "...[truncated]"
				}
				logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

				// æ„å»ºåŒ…å«é”™è¯¯å’Œusageä¿¡æ¯çš„å“åº”
				errorResponse := map[string]interface{}{
					"error": map[string]interface{}{
						"code":    "gemini_incomplete_generation",
						"message": errorMessage,
						"param":   "",
						"type":    "api_error",
					},
					"created": time.Now().Unix(),
					"data":    nil,
					"usage": map[string]interface{}{
						"total_tokens":  geminiResponse.UsageMetadata.TotalTokenCount,
						"input_tokens":  geminiResponse.UsageMetadata.PromptTokenCount,
						"output_tokens": geminiResponse.UsageMetadata.CandidatesTokenCount,
						"input_tokens_details": map[string]int{
							"text_tokens":  0,
							"image_tokens": 0,
						},
					},
				}

				// ç›´æ¥è¿”å›å“åº”
				c.JSON(http.StatusBadRequest, errorResponse)

				// è®¡ç®—è¯·æ±‚è€—æ—¶
				rowDuration := time.Since(startTime).Seconds()
				duration := math.Round(rowDuration*1000) / 1000

				// å¤„ç†é…é¢æ¶ˆè´¹ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ‰£è´¹ï¼Œå› ä¸ºå·²ç»æ¶ˆè€—äº†tokenï¼‰
				groupRatio := common.GetGroupRatio(meta.Group)
				promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
				completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

				modelRatio := common.GetModelRatio(meta.OriginModelName)
				completionRatio := common.GetCompletionRatio(meta.OriginModelName)
				actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

				logger.Infof(ctx, "Gemini JSON é”™è¯¯å“åº”å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
					promptTokens, completionTokens, groupRatio, actualQuota, duration)

				// æ¶ˆè´¹é…é¢
				err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
				if err != nil {
					logger.SysError("error consuming token remain quota: " + err.Error())
				}

				err = model.CacheUpdateUserQuota(ctx, meta.UserId)
				if err != nil {
					logger.SysError("error update user quota cache: " + err.Error())
				}

				// è®°å½•æ¶ˆè´¹æ—¥å¿—
				referer := c.Request.Header.Get("HTTP-Referer")
				title := c.Request.Header.Get("X-Title")
				tokenName := c.GetString("token_name")
				xRequestID := c.GetString("X-Request-ID")

				logContent := fmt.Sprintf("Gemini JSON Error - Model: %s, FinishReason: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
					meta.OriginModelName, candidate.FinishReason, promptTokens, completionTokens, actualQuota, duration)

				// è·å–æ¸ é“å†å²ä¿¡æ¯
				var otherInfo string
				if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
					if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
						if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
							otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
						}
					}
				}

				// è®°å½•æ—¥å¿—
				model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
					tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

				model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
				channelId := c.GetInt("channel_id")
				model.UpdateChannelUsedQuota(channelId, actualQuota)

				return nil
			}
		}

		// Convert to OpenAI DALL-E 3 format
		var imageData []struct {
			B64Json string `json:"b64_json"`
		}

		// Extract image data from Gemini response
		for i, candidate := range geminiResponse.Candidates {
			for j, part := range candidate.Content.Parts {
				if part.InlineData != nil {
					// Use the base64 data in b64_json field (OpenAI standard)
					imageData = append(imageData, struct {
						B64Json string `json:"b64_json"`
					}{
						B64Json: part.InlineData.Data,
					})
				} else if part.Text != "" {
					logger.Infof(ctx, "å€™é€‰é¡¹ #%d éƒ¨åˆ† #%d åŒ…å«æ–‡æœ¬: %s", i, j, part.Text)
				}
			}
		}

	// æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›é”™è¯¯
	if len(imageData) == 0 {
		// è¯¦ç»†åˆ†ææ— å›¾ç‰‡çš„åŸå› 
		var detailReason string
		candidatesInfo := ""
		if len(geminiResponse.Candidates) == 0 {
			detailReason = "candidates æ•°ç»„ä¸ºç©º"
		} else {
			candidate := geminiResponse.Candidates[0]
			candidatesInfo = fmt.Sprintf("finishReason=%s, partsCount=%d", 
				candidate.FinishReason, len(candidate.Content.Parts))
			
			if len(candidate.Content.Parts) == 0 {
				detailReason = "content.parts æ•°ç»„ä¸ºç©º"
			} else {
				hasText := false
				hasEmptyPart := false
				textContent := ""
				for _, part := range candidate.Content.Parts {
					if part.Text != "" {
						hasText = true
						if len(part.Text) > 50 {
							textContent = part.Text[:50] + "..."
						} else {
							textContent = part.Text
						}
					}
					if part.InlineData == nil && part.Text == "" {
						hasEmptyPart = true
					}
				}
				if hasText {
					detailReason = fmt.Sprintf("åªåŒ…å«æ–‡æœ¬ï¼Œæ²¡æœ‰å›¾ç‰‡æ•°æ®: %s", textContent)
				} else if hasEmptyPart {
					detailReason = "parts åŒ…å«ç©ºå¯¹è±¡"
				} else {
					detailReason = "æœªçŸ¥åŸå› "
				}
			}
		}
		
		logger.Errorf(ctx, "Gemini API æœªè¿”å›å›¾ç‰‡æ•°æ®: %s (%s)", detailReason, candidatesInfo)
		
		// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
		responseStr := string(responseBody)
		if len(responseStr) > 1000 {
			responseStr = responseStr[:1000] + "...[truncated]"
		}
		logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

		// æ„å»ºåŒ…å«é”™è¯¯å’Œusageä¿¡æ¯çš„å“åº”
			errorResponse := map[string]interface{}{
				"error": map[string]interface{}{
					"code":    "gemini_no_image_generated",
					"message": "Gemini API é”™è¯¯: æœªç”Ÿæˆå›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æç¤ºè¯æˆ–é‡è¯•",
					"param":   "",
					"type":    "api_error",
				},
				"created": time.Now().Unix(),
				"data":    nil,
				"usage": map[string]interface{}{
					"total_tokens":  geminiResponse.UsageMetadata.TotalTokenCount,
					"input_tokens":  geminiResponse.UsageMetadata.PromptTokenCount,
					"output_tokens": geminiResponse.UsageMetadata.CandidatesTokenCount,
					"input_tokens_details": map[string]int{
						"text_tokens":  0,
						"image_tokens": 0,
					},
				},
			}

			// ç›´æ¥è¿”å›å“åº”
			c.JSON(http.StatusBadRequest, errorResponse)

			// è®¡ç®—è¯·æ±‚è€—æ—¶
			rowDuration := time.Since(startTime).Seconds()
			duration := math.Round(rowDuration*1000) / 1000

			// å¤„ç†é…é¢æ¶ˆè´¹ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ‰£è´¹ï¼Œå› ä¸ºå·²ç»æ¶ˆè€—äº†tokenï¼‰
			groupRatio := common.GetGroupRatio(meta.Group)
			promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
			completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

			modelRatio := common.GetModelRatio(meta.OriginModelName)
			completionRatio := common.GetCompletionRatio(meta.OriginModelName)
			actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

			logger.Infof(ctx, "Gemini JSON æ— å›¾ç‰‡å“åº”å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
				promptTokens, completionTokens, groupRatio, actualQuota, duration)

			// æ¶ˆè´¹é…é¢
			err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
			if err != nil {
				logger.SysError("error consuming token remain quota: " + err.Error())
			}

			err = model.CacheUpdateUserQuota(ctx, meta.UserId)
			if err != nil {
				logger.SysError("error update user quota cache: " + err.Error())
			}

			// è®°å½•æ¶ˆè´¹æ—¥å¿—
			referer := c.Request.Header.Get("HTTP-Referer")
			title := c.Request.Header.Get("X-Title")
			tokenName := c.GetString("token_name")
			xRequestID := c.GetString("X-Request-ID")

			logContent := fmt.Sprintf("Gemini JSON No Image - Model: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
				meta.OriginModelName, promptTokens, completionTokens, actualQuota, duration)

			// è·å–æ¸ é“å†å²ä¿¡æ¯
			var otherInfo string
			if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
				if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
					if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
						otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
					}
				}
			}

			// è®°å½•æ—¥å¿—
			model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
				tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

			model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
			channelId := c.GetInt("channel_id")
			model.UpdateChannelUsedQuota(channelId, actualQuota)

			return nil
		}

		// Create OpenAI compatible response data with b64_json
		var openaiCompatibleData []struct {
			Url     string `json:"url,omitempty"`
			B64Json string `json:"b64_json,omitempty"`
		}
		for _, img := range imageData {
			openaiCompatibleData = append(openaiCompatibleData, struct {
				Url     string `json:"url,omitempty"`
				B64Json string `json:"b64_json,omitempty"`
			}{
				B64Json: img.B64Json,
			})
		}

		// ä¸º Gemini JSON è¯·æ±‚æ„å»ºåŒ…å« usage ä¿¡æ¯çš„å“åº”
		type GeminiImageResponse struct {
			Created int `json:"created"`
			Data    []struct {
				Url     string `json:"url,omitempty"`
				B64Json string `json:"b64_json,omitempty"`
			} `json:"data"`
			Usage struct {
				TotalTokens        int `json:"total_tokens"`
				InputTokens        int `json:"input_tokens"`
				OutputTokens       int `json:"output_tokens"`
				InputTokensDetails struct {
					TextTokens  int `json:"text_tokens"`
					ImageTokens int `json:"image_tokens"`
				} `json:"input_tokens_details"`
			} `json:"usage,omitempty"`
		}

		imageResponseWithUsage := GeminiImageResponse{
			Created: int(time.Now().Unix()),
			Data:    openaiCompatibleData,
			Usage: struct {
				TotalTokens        int `json:"total_tokens"`
				InputTokens        int `json:"input_tokens"`
				OutputTokens       int `json:"output_tokens"`
				InputTokensDetails struct {
					TextTokens  int `json:"text_tokens"`
					ImageTokens int `json:"image_tokens"`
				} `json:"input_tokens_details"`
			}{
				TotalTokens:  geminiResponse.UsageMetadata.TotalTokenCount,
				InputTokens:  geminiResponse.UsageMetadata.PromptTokenCount,
				OutputTokens: geminiResponse.UsageMetadata.CandidatesTokenCount,
				InputTokensDetails: struct {
					TextTokens  int `json:"text_tokens"`
					ImageTokens int `json:"image_tokens"`
				}{
					// Gemini ä¸æä¾›è¯¦ç»†çš„ token åˆ†è§£ï¼Œè®¾ä¸º 0
					TextTokens:  0,
					ImageTokens: 0,
				},
			},
		}

		// Re-marshal to the OpenAI format with usage information
		responseBody, err = json.Marshal(imageResponseWithUsage)
		if err != nil {
			logger.Errorf(ctx, "åºåˆ—åŒ–è½¬æ¢åçš„å“åº”å¤±è´¥: %s", err.Error())
			return openai.ErrorWrapper(err, "marshal_converted_response_failed", http.StatusInternalServerError)
		}

		// è®°å½• usage ä¿¡æ¯
		logger.Infof(ctx, "Gemini JSON å“åº”åŒ…å« usage ä¿¡æ¯: total_tokens=%d, input_tokens=%d, output_tokens=%d, text_tokens=%d, image_tokens=%d",
			imageResponseWithUsage.Usage.TotalTokens,
			imageResponseWithUsage.Usage.InputTokens,
			imageResponseWithUsage.Usage.OutputTokens,
			0, // Gemini ä¸æä¾›è¯¦ç»†åˆ†è§£
			0) // Gemini ä¸æä¾›è¯¦ç»†åˆ†è§£

		// å¯¹äº Gemini JSON è¯·æ±‚ï¼Œåœ¨è¿™é‡Œç›´æ¥å¤„ç†é…é¢æ¶ˆè´¹å’Œæ—¥å¿—è®°å½•
		err = handleGeminiTokenConsumption(c, ctx, meta, imageRequest, &geminiResponse, quota, startTime)
		if err != nil {
			logger.Warnf(ctx, "Gemini token consumption failed: %v", err)
		}
	} else if meta.ChannelType == 27 {
		// Handle channel type 27 response format conversion
		var channelResponse struct {
			ID   string `json:"id"`
			Data struct {
				ImageURLs []string `json:"image_urls"`
			} `json:"data"`
			Metadata struct {
				FailedCount  string `json:"failed_count"`
				SuccessCount string `json:"success_count"`
			} `json:"metadata"`
			BaseResp struct {
				StatusCode int    `json:"status_code"`
				StatusMsg  string `json:"status_msg"`
			} `json:"base_resp"`
		}

		err = json.Unmarshal(responseBody, &channelResponse)
		if err != nil {
			return openai.ErrorWrapper(err, "unmarshal_channel_response_failed", http.StatusInternalServerError)
		}

		// Convert to OpenAI DALL-E 3 format
		if channelResponse.BaseResp.StatusCode == 0 {
			var openaiImages []struct {
				Url string `json:"url"`
			}

			for _, url := range channelResponse.Data.ImageURLs {
				openaiImages = append(openaiImages, struct {
					Url string `json:"url"`
				}{
					Url: url,
				})
			}
			// Create a compatible slice with the correct struct type
			var compatibleImages []struct {
				Url string `json:"url"`
			}
			for _, img := range openaiImages {
				compatibleImages = append(compatibleImages, struct {
					Url string `json:"url"`
				}{
					Url: img.Url,
				})
			}

			// Create a compatible slice with the correct struct type for OpenAI response
			var openaiCompatibleImages []struct {
				Url     string `json:"url,omitempty"`
				B64Json string `json:"b64_json,omitempty"`
			}
			for _, img := range compatibleImages {
				openaiCompatibleImages = append(openaiCompatibleImages, struct {
					Url     string `json:"url,omitempty"`
					B64Json string `json:"b64_json,omitempty"`
				}{
					Url: img.Url,
				})
			}

			imageResponse = openai.ImageResponse{
				Created: int(time.Now().Unix()),
				Data:    openaiCompatibleImages,
			}

			// Re-marshal to the OpenAI format
			responseBody, err = json.Marshal(imageResponse)
			if err != nil {
				return openai.ErrorWrapper(err, "marshal_converted_response_failed", http.StatusInternalServerError)
			}
		} else {
			// If there's an error in the original response, keep it as is
			return openai.ErrorWrapper(
				fmt.Errorf("channel error: %s (code: %d)",
					channelResponse.BaseResp.StatusMsg,
					channelResponse.BaseResp.StatusCode),
				"channel_error",
				http.StatusInternalServerError,
			)
		}
	} else {
		// For other channel types, unmarshal as usual
		err = json.Unmarshal(responseBody, &imageResponse)
		if err != nil {
			return openai.ErrorWrapper(err, "unmarshal_response_body_failed", http.StatusInternalServerError)
		}
	}

	// è®¾ç½®å“åº”å¤´ï¼Œæ’é™¤Content-Lengthï¼ˆè®©Ginè‡ªåŠ¨å¤„ç†ï¼‰
	for k, v := range resp.Header {
		// è·³è¿‡Content-Lengthï¼Œè®©Ginæ¡†æ¶è‡ªåŠ¨è®¡ç®—æ­£ç¡®çš„å€¼
		if strings.ToLower(k) != "content-length" {
			c.Writer.Header().Set(k, v[0])
		}
	}

	// æ³¨æ„ï¼šä¸æ‰‹åŠ¨è®¾ç½®Content-Lengthï¼Œè®©Ginçš„c.Data()è‡ªåŠ¨è®¡ç®—
	// è®°å½•å“åº”ä½“å¤§å°ç”¨äºè°ƒè¯•
	logger.Debugf(ctx, "Response body size: %d bytes", len(responseBody))

	// ä½¿ç”¨c.Data()è®©Ginè‡ªåŠ¨å¤„ç†Content-Lengthå’Œå“åº”å†™å…¥
	c.Data(resp.StatusCode, c.Writer.Header().Get("Content-Type"), responseBody)

	// æ£€æŸ¥å‡½æ•°ç»“æŸæ—¶çš„ä¸Šä¸‹æ–‡çŠ¶æ€
	if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
		logger.Infof(ctx, "RelayImageHelper: EXIT SUCCESS - admin_channel_history exists: %v", channelHistoryInterface)
	} else {
		logger.Warnf(ctx, "RelayImageHelper: EXIT SUCCESS - admin_channel_history NOT found (this is the problem!)")
	}

	logger.Infof(ctx, "RelayImageHelper EXIT SUCCESS: returning nil")
	return nil
}

// è®¡ç®—æœ€å¤§å…¬çº¦æ•°
func gcd(a, b int) int {
	for b != 0 {
		a, b = b, a%b
	}
	return a
}

// æ·»åŠ è¾…åŠ©å‡½æ•°ç”¨äºè½¬ä¹‰å¼•å· (åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ )
func escapeQuotes(s string) string {
	return strings.Replace(s, `"`, `\"`, -1)
}

func DoImageRequest(c *gin.Context, modelName string) *relaymodel.ErrorWithStatusCode {
	ctx := c.Request.Context()
	meta := util.GetRelayMeta(c)
	if strings.HasPrefix(modelName, "kling") {
		return handleKlingImageRequest(c, ctx, modelName, meta)
	} else if strings.HasPrefix(modelName, "flux") {
		return handleFluxImageRequest(c, ctx, modelName, meta)
	} else if strings.HasPrefix(modelName, "wan") {
		return handleAliImageRequest(c, ctx, modelName, meta)
	}
	// éœ€è¦æ·»åŠ å¤„ç†å…¶ä»–æ¨¡å‹ç±»å‹çš„é€»è¾‘
	return openai.ErrorWrapper(fmt.Errorf("unsupported model: %s", modelName), "unsupported_model", http.StatusBadRequest)
}

func handleFluxImageRequest(c *gin.Context, ctx context.Context, modelName string, meta *util.RelayMeta) *relaymodel.ErrorWithStatusCode {
	baseUrl := meta.BaseURL
	// ç›´æ¥ä½¿ç”¨æ¨¡å‹åç§°æ„å»ºURL

	fullRequestUrl := ""
	if meta.ChannelType == 46 { //flux
		fullRequestUrl = fmt.Sprintf("%s/v1/%s", baseUrl, modelName)
	} else {
		fullRequestUrl = fmt.Sprintf("%s/flux/v1/%s", baseUrl, modelName)
	}

	// Read the original request body
	bodyBytes, err := io.ReadAll(c.Request.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_request_body_failed", http.StatusBadRequest)
	}

	// Restore the request body for further use
	c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

	// Parse the request body
	var requestMap map[string]interface{}
	if err := json.Unmarshal(bodyBytes, &requestMap); err != nil {
		return openai.ErrorWrapper(err, "unmarshal_request_body_failed", http.StatusBadRequest)
	}

	// Determine the mode based on whether an image_prompt parameter exists
	mode := "texttoimage"
	if _, hasImagePrompt := requestMap["image_prompt"]; hasImagePrompt {
		mode = "imagetoimage"
	}

	logger.Debugf(ctx, "Flux API request mode: %s, model: %s", mode, modelName)

	// Remove the 'model' parameter as Flux API doesn't need it
	delete(requestMap, "model")

	// Re-marshal the modified request
	modifiedBody, err := json.Marshal(requestMap)
	if err != nil {
		return openai.ErrorWrapper(err, "marshal_modified_request_failed", http.StatusInternalServerError)
	}

	// Create a new request with the modified body
	req, err := http.NewRequest(c.Request.Method, fullRequestUrl, bytes.NewBuffer(modifiedBody))
	if err != nil {
		return openai.ErrorWrapper(err, "create_request_failed", http.StatusInternalServerError)
	}

	// Set headers
	req.Header.Set("Content-Type", "application/json")
	if meta.ChannelType == 46 {
		req.Header.Set("x-key", meta.APIKey)
	} else {
		req.Header.Set("Authorization", "Bearer "+meta.APIKey)
	}

	// Send the request
	resp, err := util.HTTPClient.Do(req)
	if err != nil {
		return openai.ErrorWrapper(err, "do_request_failed", http.StatusInternalServerError)
	}
	defer resp.Body.Close()

	// Read the response body
	responseBody, err := io.ReadAll(resp.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_response_body_failed", http.StatusInternalServerError)
	}

	// åœ¨è®°å½•æ—¥å¿—æ—¶ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼
	logger.Infof(ctx, "Flux API response status: %d, body: %s", resp.StatusCode, string(responseBody))

	// Check if the request was successful
	if resp.StatusCode != http.StatusOK {
		// Handle error response (status code 422 or others)
		if resp.StatusCode == http.StatusUnprocessableEntity {
			// Parse error response format
			var fluxError struct {
				Detail []struct {
					Loc  []string `json:"loc"`
					Msg  string   `json:"msg"`
					Type string   `json:"type"`
				} `json:"detail"`
			}

			if err := json.Unmarshal(responseBody, &fluxError); err == nil && len(fluxError.Detail) > 0 {
				errorMsg := fmt.Sprintf("Flux API validation error: %s", fluxError.Detail[0].Msg)
				return openai.ErrorWrapper(
					fmt.Errorf(errorMsg),
					"flux_validation_error",
					resp.StatusCode,
				)
			}
		}

		return openai.ErrorWrapper(
			fmt.Errorf("Flux API error: status code %d, response: %s", resp.StatusCode, string(responseBody)),
			"flux_api_error",
			resp.StatusCode,
		)
	}

	// Parse the Flux API successful response
	var fluxResponse struct {
		ID         string `json:"id"`
		PollingURL string `json:"polling_url"`
	}

	if err := json.Unmarshal(responseBody, &fluxResponse); err != nil {
		return openai.ErrorWrapper(err, "unmarshal_response_body_failed", http.StatusInternalServerError)
	}

	// è®¡ç®—é…é¢ï¼ˆåœ¨è®°å½•æ—¥å¿—ä¹‹å‰ï¼‰
	quota := calculateImageQuota(modelName, mode, 1)

	// è®°å½•å›¾åƒç”Ÿæˆæ—¥å¿—
	err = CreateImageLog(
		"flux",          // provider
		fluxResponse.ID, // taskId
		meta,            // meta
		"submitted",     // status (Flux API æäº¤æˆåŠŸåçš„åˆå§‹çŠ¶æ€)
		"",              // failReason (ç©ºï¼Œå› ä¸ºè¯·æ±‚æˆåŠŸ)
		mode,            // modeå‚æ•°
		1,               // nå‚æ•°
		quota,           // quotaå‚æ•°

	)
	if err != nil {
		logger.Warnf(ctx, "Failed to create image log: %v", err)
		// ç»§ç»­å¤„ç†ï¼Œä¸å› æ—¥å¿—è®°å½•å¤±è´¥è€Œä¸­æ–­å“åº”
	}

	// Convert to the format expected by the client
	asyncResponse := relaymodel.GeneralImageResponseAsync{
		TaskId:     fluxResponse.ID,
		Message:    "Request submitted successfully",
		TaskStatus: "succeed", // è¯·æ±‚æäº¤æˆåŠŸ
	}

	// Marshal the response
	responseJSON, err := json.Marshal(asyncResponse)
	if err != nil {
		return openai.ErrorWrapper(err, "marshal_response_failed", http.StatusInternalServerError)
	}

	// Set response headers
	c.Writer.Header().Set("Content-Type", "application/json")
	c.Writer.Header().Set("Content-Length", strconv.Itoa(len(responseJSON)))

	// Write the response
	c.Writer.WriteHeader(http.StatusOK)
	_, err = c.Writer.Write(responseJSON)
	if err != nil {
		return openai.ErrorWrapper(err, "write_response_failed", http.StatusInternalServerError)
	}

	// Handle billing based on mode, modelName and number of images (n)
	err = handleSuccessfulResponseImage(c, ctx, meta, modelName, mode, 1)
	if err != nil {
		logger.Warnf(ctx, "Failed to process billing: %v", err)
		// Continue processing, don't interrupt the response due to billing failure
	}

	return nil
}

func handleKlingImageRequest(c *gin.Context, ctx context.Context, modelName string, meta *util.RelayMeta) *relaymodel.ErrorWithStatusCode {
	baseUrl := meta.BaseURL
	var fullRequestUrl string

	if meta.ChannelType == 41 {
		fullRequestUrl = fmt.Sprintf("%s/v1/images/generations", baseUrl)
	} else {
		fullRequestUrl = fmt.Sprintf("%s/kling/v1/images/generations", baseUrl)
	}

	// Read the original request body
	bodyBytes, err := io.ReadAll(c.Request.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_request_body_failed", http.StatusBadRequest)
	}

	// Restore the request body for further use
	c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

	// Parse the request body
	var requestMap map[string]interface{}
	if err := json.Unmarshal(bodyBytes, &requestMap); err != nil {
		return openai.ErrorWrapper(err, "unmarshal_request_body_failed", http.StatusBadRequest)
	}

	// Extract the 'n' parameter (number of images) from the request
	n := 1 // Default to 1 if not specified
	if nValue, ok := requestMap["n"]; ok {
		// Try to convert to float64 first (JSON numbers are decoded as float64)
		if nFloat, ok := nValue.(float64); ok {
			n = int(nFloat)
		} else if nInt, ok := nValue.(int); ok {
			// Also try int just in case
			n = nInt
		} else if nString, ok := nValue.(string); ok {
			// Also try string conversion
			if nInt, err := strconv.Atoi(nString); err == nil {
				n = nInt
			}
		}
	}

	// Ensure n is at least 1
	if n < 1 {
		n = 1
	}

	// Determine the mode based on whether an image parameter exists
	mode := "texttoimage"
	if _, hasImage := requestMap["image"]; hasImage {
		mode = "imagetoimage"
	}

	logger.Debugf(ctx, "Kling API request mode: %s, generating %d images", mode, n)

	// Transform 'model' to 'model_name'
	if model, ok := requestMap["model"]; ok {
		requestMap["model_name"] = model
		delete(requestMap, "model")
	}

	// Re-marshal the modified request
	modifiedBody, err := json.Marshal(requestMap)
	if err != nil {
		return openai.ErrorWrapper(err, "marshal_modified_request_failed", http.StatusInternalServerError)
	}

	// Create a new request with the modified body
	req, err := http.NewRequest(c.Request.Method, fullRequestUrl, bytes.NewBuffer(modifiedBody))
	if err != nil {
		return openai.ErrorWrapper(err, "create_request_failed", http.StatusInternalServerError)
	}

	var token string

	if meta.ChannelType == 41 {
		ak := meta.Config.AK
		sk := meta.Config.SK

		// Generate JWT token
		token = EncodeJWTToken(ak, sk)
	} else {
		token = meta.APIKey
	}
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+token)

	// Send the request
	resp, err := util.HTTPClient.Do(req)
	if err != nil {
		return openai.ErrorWrapper(err, "do_request_failed", http.StatusInternalServerError)
	}
	defer resp.Body.Close()

	// Read the response body
	responseBody, err := io.ReadAll(resp.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_response_body_failed", http.StatusInternalServerError)
	}

	// åœ¨è®°å½•æ—¥å¿—æ—¶ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼
	logger.Infof(ctx, "Kling API modified request: %s", string(responseBody))
	// Parse the Kling API response
	var klingImageResponse keling.KlingImageResponse

	if err := json.Unmarshal(responseBody, &klingImageResponse); err != nil {
		return openai.ErrorWrapper(err, "unmarshal_response_body_failed", http.StatusInternalServerError)
	}

	// æ£€æŸ¥é”™è¯¯æ—¶æä¾›æ›´è¯¦ç»†çš„ä¿¡æ¯
	if klingImageResponse.Code != 0 {
		return openai.ErrorWrapper(
			fmt.Errorf("Kling API error: %s (code: %d, task_id: %s)",
				klingImageResponse.Message,
				klingImageResponse.Code,
				klingImageResponse.Data.TaskID),
			"kling_api_error",
			http.StatusBadRequest,
		)
	}

	// è®¡ç®—é…é¢ï¼ˆåœ¨è®°å½•æ—¥å¿—ä¹‹å‰ï¼‰
	quota := calculateImageQuota(modelName, mode, n)

	// è®°å½•å›¾åƒç”Ÿæˆæ—¥å¿—ï¼Œä¼ é€’modeå‚æ•°
	err = CreateImageLog(
		"kling",                            // provider
		klingImageResponse.Data.TaskID,     // taskId
		meta,                               // meta
		klingImageResponse.Data.TaskStatus, // status
		"",                                 // failReason (ç©ºï¼Œå› ä¸ºè¯·æ±‚æˆåŠŸ)
		mode,                               // æ–°å¢çš„modeå‚æ•°
		n,                                  // æ–°å¢çš„nå‚æ•°
		quota,                              // æ–°å¢çš„quotaå‚æ•°
	)
	if err != nil {
		logger.Warnf(ctx, "Failed to create image log: %v", err)
		// ç»§ç»­å¤„ç†ï¼Œä¸å› æ—¥å¿—è®°å½•å¤±è´¥è€Œä¸­æ–­å“åº”
	}

	// Convert to the format expected by the client
	asyncResponse := relaymodel.GeneralImageResponseAsync{
		TaskId:  klingImageResponse.Data.TaskID,
		Message: klingImageResponse.Message,
	}

	// Normalize task status to match the expected format (only "failed" or "succeed")
	switch klingImageResponse.Data.TaskStatus {
	case "failed":
		asyncResponse.TaskStatus = "failed"
	default:
		asyncResponse.TaskStatus = "succeed"
	}

	// Marshal the response
	responseJSON, err := json.Marshal(asyncResponse)
	if err != nil {
		return openai.ErrorWrapper(err, "marshal_response_failed", http.StatusInternalServerError)
	}

	// Set response headers
	c.Writer.Header().Set("Content-Type", "application/json")
	c.Writer.Header().Set("Content-Length", strconv.Itoa(len(responseJSON)))

	// Write the response
	c.Writer.WriteHeader(http.StatusOK)
	_, err = c.Writer.Write(responseJSON)
	if err != nil {
		return openai.ErrorWrapper(err, "write_response_failed", http.StatusInternalServerError)
	}

	// Handle billing based on mode, modelName and number of images (n)
	err = handleSuccessfulResponseImage(c, ctx, meta, modelName, mode, n)
	if err != nil {
		logger.Warnf(ctx, "Failed to process billing: %v", err)
		// Continue processing, don't interrupt the response due to billing failure
	}

	return nil
}

func handleAliImageRequest(c *gin.Context, ctx context.Context, modelName string, meta *util.RelayMeta) *relaymodel.ErrorWithStatusCode {
	baseUrl := meta.BaseURL

	// æ„å»ºé˜¿é‡Œäº‘ä¸‡ç›¸API URL
	fullRequestUrl := fmt.Sprintf("%s/api/v1/services/aigc/image2image/image-synthesis", baseUrl)

	// Read the original request body
	bodyBytes, err := io.ReadAll(c.Request.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_request_body_failed", http.StatusBadRequest)
	}

	// Restore the request body for further use
	c.Request.Body = io.NopCloser(bytes.NewBuffer(bodyBytes))

	// Parse the request body to extract parameters for logging
	var requestMap map[string]interface{}
	if err := json.Unmarshal(bodyBytes, &requestMap); err != nil {
		return openai.ErrorWrapper(err, "unmarshal_request_body_failed", http.StatusBadRequest)
	}

	// Extract the 'n' parameter (number of images) from the request
	// Check both root level and parameters level
	n := 4 // Default to 1 if not specified

	// First check root level (for backward compatibility)
	if nValue, ok := requestMap["n"]; ok {
		if nFloat, ok := nValue.(float64); ok {
			n = int(nFloat)
		} else if nInt, ok := nValue.(int); ok {
			n = nInt
		}
	} else if params, ok := requestMap["parameters"]; ok {
		// Check parameters object for n value
		if paramsMap, ok := params.(map[string]interface{}); ok {
			if nValue, ok := paramsMap["n"]; ok {
				if nFloat, ok := nValue.(float64); ok {
					n = int(nFloat)
				} else if nInt, ok := nValue.(int); ok {
					n = nInt
				}
			}
		}
	}

	// Ensure n is at least 1
	if n < 1 {
		n = 1
	}

	// Determine the mode based on whether images parameter exists
	mode := "imagetoimage"
	// if images, ok := requestMap["images"]; ok {
	// 	if imageArray, ok := images.([]interface{}); ok && len(imageArray) > 0 {
	// 		mode = "imagetoimage"
	// 	}
	// }

	logger.Debugf(ctx, "Ali Wan API request mode: %s, model: %s, generating %d images", mode, modelName, n)

	// Create a new request with the original body (no transformation needed)
	req, err := http.NewRequest(c.Request.Method, fullRequestUrl, bytes.NewBuffer(bodyBytes))
	if err != nil {
		return openai.ErrorWrapper(err, "create_request_failed", http.StatusInternalServerError)
	}

	// Set headers for Ali Wan API
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+meta.APIKey)
	req.Header.Set("X-DashScope-Async", "enable") // å¿…é¡»è®¾ç½®ä¸ºå¼‚æ­¥æ¨¡å¼

	// Send the request
	resp, err := util.HTTPClient.Do(req)
	if err != nil {
		return openai.ErrorWrapper(err, "do_request_failed", http.StatusInternalServerError)
	}
	defer resp.Body.Close()

	// Read the response body
	responseBody, err := io.ReadAll(resp.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_response_body_failed", http.StatusInternalServerError)
	}

	logger.Infof(ctx, "Ali Wan API response status: %d, body: %s", resp.StatusCode, string(responseBody))

	// Parse response regardless of status code
	var aliResponse struct {
		RequestId string `json:"request_id,omitempty"`
		Output    struct {
			TaskId     string `json:"task_id,omitempty"`
			TaskStatus string `json:"task_status,omitempty"`
		} `json:"output,omitempty"`
		Code    string `json:"code,omitempty"`
		Message string `json:"message,omitempty"`
	}

	if err := json.Unmarshal(responseBody, &aliResponse); err != nil {
		return openai.ErrorWrapper(err, "unmarshal_response_body_failed", http.StatusInternalServerError)
	}

	// Check if the request was successful
	var asyncResponse relaymodel.GeneralImageResponseAsync

	if resp.StatusCode != http.StatusOK || aliResponse.Code != "" {
		// Handle error case - convert to failed async response
		errorMessage := fmt.Sprintf("Ali API error (status: %d)", resp.StatusCode)
		if aliResponse.Code != "" && aliResponse.Message != "" {
			errorMessage = fmt.Sprintf("%s (code: %s)", aliResponse.Message, aliResponse.Code)
		}

		asyncResponse = relaymodel.GeneralImageResponseAsync{
			TaskId:     "", // No task ID for failed requests
			Message:    errorMessage,
			TaskStatus: "failed",
		}

		logger.Warnf(ctx, "Ali Wan API request failed: %s", errorMessage)
	} else {
		// Handle success case
		asyncResponse = relaymodel.GeneralImageResponseAsync{
			TaskId:     aliResponse.Output.TaskId,
			Message:    "Request submitted successfully",
			TaskStatus: "succeed",
		}

		// è®¡ç®—é…é¢
		quota := calculateImageQuota(modelName, mode, n)

		// è®°å½•å›¾åƒç”Ÿæˆæ—¥å¿—
		err = CreateImageLog(
			"ali",                     // provider
			aliResponse.Output.TaskId, // taskId
			meta,                      // meta
			"submitted",               // status (Ali API æäº¤æˆåŠŸåçš„åˆå§‹çŠ¶æ€)
			"",                        // failReason (ç©ºï¼Œå› ä¸ºè¯·æ±‚æˆåŠŸ)
			mode,                      // modeå‚æ•°
			n,                         // nå‚æ•°
			quota,                     // quotaå‚æ•°
		)
		if err != nil {
			logger.Warnf(ctx, "Failed to create image log: %v", err)
			// ç»§ç»­å¤„ç†ï¼Œä¸å› æ—¥å¿—è®°å½•å¤±è´¥è€Œä¸­æ–­å“åº”
		}

		// Handle billing based on mode, modelName and number of images (n)
		err = handleSuccessfulResponseImage(c, ctx, meta, modelName, mode, n)
		if err != nil {
			logger.Warnf(ctx, "Failed to process billing: %v", err)
			// Continue processing, don't interrupt the response due to billing failure
		}
	}

	// Marshal the response
	responseJSON, err := json.Marshal(asyncResponse)
	if err != nil {
		return openai.ErrorWrapper(err, "marshal_response_failed", http.StatusInternalServerError)
	}

	// Set response headers
	c.Writer.Header().Set("Content-Type", "application/json")
	c.Writer.Header().Set("Content-Length", strconv.Itoa(len(responseJSON)))

	// Write the response
	c.Writer.WriteHeader(http.StatusOK)
	_, err = c.Writer.Write(responseJSON)
	if err != nil {
		return openai.ErrorWrapper(err, "write_response_failed", http.StatusInternalServerError)
	}

	return nil
}

// æ›´æ–° CreateImageLog å‡½æ•°ä»¥æ¥å— mode å‚æ•°
func CreateImageLog(provider string, taskId string, meta *util.RelayMeta, status string, failReason string, mode string, n int, quota int64) error {
	// åˆ›å»ºæ–°çš„ Image å®ä¾‹
	image := &model.Image{
		Username:   model.GetUsernameById(meta.UserId),
		ChannelId:  meta.ChannelId,
		UserId:     meta.UserId,
		Model:      meta.OriginModelName,
		Status:     status,
		FailReason: failReason,
		Provider:   provider,
		CreatedAt:  time.Now().Unix(), // ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
		TaskId:     taskId,
		Mode:       mode, // æ·»åŠ  mode å­—æ®µ
		N:          n,    // æ·»åŠ  n å­—æ®µ
		Quota:      quota,
		Detail:     "",
	}

	// è°ƒç”¨ Insert æ–¹æ³•æ’å…¥è®°å½•
	err := image.Insert()
	if err != nil {
		return fmt.Errorf("failed to insert image log: %v", err)
	}

	return nil
}

// calculateImageQuota è®¡ç®—å›¾åƒç”Ÿæˆçš„é…é¢
func calculateImageQuota(modelName string, mode string, n int) int64 {
	var modelPrice float64

	// Flux API official pricing - https://bfl.ai/pricing/api
	switch modelName {
	// FLUX Models
	case "flux-kontext-max":
		modelPrice = 0.08
	case "flux-kontext-pro":
		modelPrice = 0.04
	case "flux-pro-1.1-ultra":
		modelPrice = 0.06
	case "flux-pro-1.1":
		modelPrice = 0.04
	case "flux-pro":
		modelPrice = 0.05
	case "flux-dev":
		modelPrice = 0.025
	// FLUX.1 Tools
	case "flux-pro-1.0-fill":
		modelPrice = 0.05
	case "flux-pro-1.0-canny":
		modelPrice = 0.05
	case "flux-pro-1.0-depth":
		modelPrice = 0.05
	case "wan2.5-i2i-preview":
		modelPrice = 0.2
	// Legacy Kling models (keep existing logic for compatibility)
	default:
		if strings.Contains(modelName, "kling") {
			// Keep original Kling pricing logic
			basePrice := 0.025
			var multiplier float64 = 1.0

			if strings.Contains(modelName, "v1.0") {
				multiplier = 1.0
			} else if strings.Contains(modelName, "v1.5") {
				if mode == "texttoimage" {
					multiplier = 4.0
				} else if mode == "imagetoimage" {
					multiplier = 8.0
				}
			} else if strings.Contains(modelName, "v2") {
				multiplier = 4.0
			} else {
				multiplier = 4.0
			}
			modelPrice = basePrice * multiplier
		} else {
			// Default price for unknown models
			modelPrice = 0.05
		}
	}

	// Calculate quota based on model price and number of images
	quota := int64(modelPrice*500000) * int64(n)
	return quota
}

// Update handleSuccessfulResponseImage to accept mode and n parameters
func handleSuccessfulResponseImage(c *gin.Context, ctx context.Context, meta *util.RelayMeta, modelName string, mode string, n int) error {
	// Calculate quota using the new function
	quota := calculateImageQuota(modelName, mode, n)

	referer := c.Request.Header.Get("HTTP-Referer")
	title := c.Request.Header.Get("X-Title")

	err := model.PostConsumeTokenQuota(meta.TokenId, quota)
	if err != nil {
		logger.SysError("error consuming token remain quota: " + err.Error())
		return err
	}

	err = model.CacheUpdateUserQuota(ctx, meta.UserId)
	if err != nil {
		logger.SysError("error update user quota cache: " + err.Error())
		return err
	}

	if quota != 0 {
		tokenName := c.GetString("token_name")
		xRequestID := c.GetString("X-Request-ID")
		// Include pricing details in log content
		totalCost := float64(quota) / 500000
		logContent := fmt.Sprintf("Mode: %s, Images: %d, Total cost: $%.3f",
			mode, n, totalCost)

		// è·å–æ¸ é“å†å²ä¿¡æ¯å¹¶è®°å½•æ—¥å¿—
		var otherInfo string
		if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
			if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
				if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
					otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
				}
			}
		}

		if otherInfo != "" {
			model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, 0, 0, modelName, tokenName, quota, logContent, 0, title, referer, false, 0.0, otherInfo, xRequestID)
		} else {
			model.RecordConsumeLogWithRequestID(ctx, meta.UserId, meta.ChannelId, 0, 0, modelName, tokenName, quota, logContent, 0, title, referer, false, 0.0, xRequestID)
		}
		model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, quota)
		channelId := c.GetInt("channel_id")
		model.UpdateChannelUsedQuota(channelId, quota)
	}

	return nil
}

func GetImageResult(c *gin.Context, taskId string) *relaymodel.ErrorWithStatusCode {
	image, err := model.GetImageByTaskId(taskId)
	if err != nil {
		return openai.ErrorWrapper(err, "failed to get image", http.StatusInternalServerError)
	}
	channel, err := model.GetChannelById(image.ChannelId, true)
	cfg, _ := channel.LoadConfig()
	if err != nil {
		return openai.ErrorWrapper(err, "failed to get channel", http.StatusInternalServerError)
	}

	var fullRequestUrl string
	var req *http.Request

	switch image.Provider {
	case "kling":
		fullRequestUrl = fmt.Sprintf("%s/kling/v1/images/generations/%s", *channel.BaseURL, taskId)
		req, err = http.NewRequest("GET", fullRequestUrl, nil)
		if err != nil {
			return openai.ErrorWrapper(
				fmt.Errorf("failed to create request: %v", err),
				"api_error",
				http.StatusInternalServerError,
			)
		}
	case "flux":
		// Flux API ä½¿ç”¨ GET è¯·æ±‚æŸ¥è¯¢ç»“æœï¼Œå¸¦æŸ¥è¯¢å‚æ•° id
		if channel.Type == 46 {
			fullRequestUrl = fmt.Sprintf("%s/v1/get_result?id=%s", *channel.BaseURL, taskId)
		} else {
			fullRequestUrl = fmt.Sprintf("%s/flux/v1/get_result?id=%s", *channel.BaseURL, taskId)
		}

		req, err = http.NewRequest("GET", fullRequestUrl, nil)
		if err != nil {
			return openai.ErrorWrapper(
				fmt.Errorf("failed to create request: %v", err),
				"api_error",
				http.StatusInternalServerError,
			)
		}
	case "ali":
		// é˜¿é‡Œäº‘ä¸‡ç›¸APIæŸ¥è¯¢ç»“æœæ¥å£
		fullRequestUrl = fmt.Sprintf("%s/api/v1/tasks/%s", *channel.BaseURL, taskId)
		req, err = http.NewRequest("GET", fullRequestUrl, nil)
		if err != nil {
			return openai.ErrorWrapper(
				fmt.Errorf("failed to create request: %v", err),
				"api_error",
				http.StatusInternalServerError,
			)
		}
	default:
		req, err = http.NewRequest("GET", fullRequestUrl, nil)
		if err != nil {
			return openai.ErrorWrapper(
				fmt.Errorf("failed to create request: %v", err),
				"api_error",
				http.StatusInternalServerError,
			)
		}
	}
	if image.Provider == "kling" && channel.Type == 41 {
		token := EncodeJWTToken(cfg.AK, cfg.SK)

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("Authorization", "Bearer "+token)

	} else if image.Provider == "flux" && channel.Type == 46 {
		req.Header.Set("x-key", channel.Key)
	} else {
		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("Authorization", "Bearer "+channel.Key)
	}

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return openai.ErrorWrapper(
			fmt.Errorf("failed to fetch video result: %v", err),
			"api_error",
			http.StatusInternalServerError,
		)
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return openai.ErrorWrapper(
			fmt.Errorf("failed to read response body: %v", err),
			"api_error",
			http.StatusInternalServerError,
		)
	}

	// Log the original response body for debugging
	logger.Infof(c.Request.Context(), "%s image result original response: %s", image.Provider, string(body))

	if resp.StatusCode != http.StatusOK {
		return openai.ErrorWrapper(
			fmt.Errorf("API error: %s", string(body)),
			"api_error",
			resp.StatusCode,
		)
	}

	// Create the final response
	finalResponse := relaymodel.GeneralFinalImageResponseAsync{
		TaskId: taskId,
	}

	switch image.Provider {
	case "kling":
		var klingImageResult keling.KlingImageResult
		if err := json.Unmarshal(body, &klingImageResult); err != nil {
			return openai.ErrorWrapper(
				fmt.Errorf("failed to unmarshal response body: %v", err),
				"api_error",
				http.StatusInternalServerError,
			)
		}

		if klingImageResult.Code != 0 {
			return openai.ErrorWrapper(
				fmt.Errorf("Kling API error: %s (code: %d)", klingImageResult.Message, klingImageResult.Code),
				"api_error",
				http.StatusInternalServerError,
			)
		}

		finalResponse.Message = klingImageResult.Message

		// å¤„ç†ä»»åŠ¡çŠ¶æ€ï¼Œå°† submitted ä¹Ÿå¤„ç†ä¸º processing
		if klingImageResult.Data.TaskStatus == "submitted" {
			finalResponse.TaskStatus = "processing"
		} else {
			finalResponse.TaskStatus = klingImageResult.Data.TaskStatus
		}

		// Check if there are images in the result and the task is completed
		if klingImageResult.Data.TaskStatus == "succeed" &&
			len(klingImageResult.Data.TaskResult.Images) > 0 {
			// Create an array to store all image URLs
			var imageUrls []string
			for _, image := range klingImageResult.Data.TaskResult.Images {
				if image.URL != "" {
					imageUrls = append(imageUrls, image.URL)
				}
			}

			// Add all image URLs to the response
			finalResponse.ImageUrls = imageUrls
			finalResponse.ImageId = klingImageResult.Data.TaskID
		}

	case "flux":
		// Check for error response first (422 status code)
		if resp.StatusCode == http.StatusUnprocessableEntity {
			var fluxError struct {
				Detail []struct {
					Loc  []string `json:"loc"`
					Msg  string   `json:"msg"`
					Type string   `json:"type"`
				} `json:"detail"`
			}

			if err := json.Unmarshal(body, &fluxError); err == nil && len(fluxError.Detail) > 0 {
				errorMsg := fmt.Sprintf("Flux API validation error: %s", fluxError.Detail[0].Msg)
				return openai.ErrorWrapper(
					fmt.Errorf(errorMsg),
					"flux_validation_error",
					resp.StatusCode,
				)
			}
		}

		var fluxImageResult struct {
			ID       string                 `json:"id"`
			Status   string                 `json:"status"`
			Result   interface{}            `json:"result,omitempty"`
			Progress int                    `json:"progress,omitempty"`
			Details  map[string]interface{} `json:"details,omitempty"`
			Preview  map[string]interface{} `json:"preview,omitempty"`
		}

		if err := json.Unmarshal(body, &fluxImageResult); err != nil {
			return openai.ErrorWrapper(
				fmt.Errorf("failed to unmarshal flux response body: %v", err),
				"api_error",
				http.StatusInternalServerError,
			)
		}

		// å¤„ç†ä»»åŠ¡çŠ¶æ€æ˜ å°„å’Œæ¶ˆæ¯
		switch fluxImageResult.Status {
		case "Ready":
			finalResponse.TaskStatus = "succeed"
			finalResponse.Message = "Image generation completed"
			// å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œresult å­—æ®µåŒ…å«å›¾åƒURL
			if fluxImageResult.Result != nil {
				if resultMap, ok := fluxImageResult.Result.(map[string]interface{}); ok {
					if sample, exists := resultMap["sample"]; exists {
						if sampleStr, ok := sample.(string); ok && sampleStr != "" {
							finalResponse.ImageUrls = []string{sampleStr}
							finalResponse.ImageId = fluxImageResult.ID
						}
					}
				} else if resultStr, ok := fluxImageResult.Result.(string); ok && resultStr != "" {
					// å¦‚æœ result ç›´æ¥æ˜¯å­—ç¬¦ä¸²ï¼ˆå›¾åƒURLï¼‰
					finalResponse.ImageUrls = []string{resultStr}
					finalResponse.ImageId = fluxImageResult.ID
				}
			}
		case "Task not found":
			finalResponse.TaskStatus = "failed"
			finalResponse.Message = "Task not found"
		case "Pending":
			finalResponse.TaskStatus = "processing"
			finalResponse.Message = "Task is pending, please check later"
		case "Request Moderated":
			finalResponse.TaskStatus = "failed"
			// æå–è¯·æ±‚å®¡æ ¸å¤±è´¥çš„å…·ä½“åŸå› 
			if fluxImageResult.Details != nil {
				if moderationReasons, exists := fluxImageResult.Details["Moderation Reasons"]; exists {
					if reasons, ok := moderationReasons.([]interface{}); ok && len(reasons) > 0 {
						finalResponse.Message = fmt.Sprintf("Request moderated: %v", reasons[0])
					} else {
						finalResponse.Message = "Request moderated"
					}
				} else {
					finalResponse.Message = "Request moderated"
				}
			} else {
				finalResponse.Message = "Request moderated"
			}
		case "Content Moderated":
			finalResponse.TaskStatus = "failed"
			// æå–å†…å®¹å®¡æ ¸å¤±è´¥çš„å…·ä½“åŸå› 
			if fluxImageResult.Details != nil {
				if moderationReasons, exists := fluxImageResult.Details["Moderation Reasons"]; exists {
					if reasons, ok := moderationReasons.([]interface{}); ok && len(reasons) > 0 {
						finalResponse.Message = fmt.Sprintf("Content moderated: %v", reasons[0])
					} else {
						finalResponse.Message = "Content moderated"
					}
				} else {
					finalResponse.Message = "Content moderated"
				}
			} else {
				finalResponse.Message = "Content moderated"
			}
		case "Error":
			finalResponse.TaskStatus = "failed"
			finalResponse.Message = "Image generation failed"
		default:
			// å…¶ä»–æœªçŸ¥çŠ¶æ€
			finalResponse.TaskStatus = "processing"
			finalResponse.Message = fmt.Sprintf("Task processing (status: %s)", fluxImageResult.Status)
		}

	case "ali":
		// é˜¿é‡Œäº‘ä¸‡ç›¸APIå“åº”ç»“æ„
		var aliResponse struct {
			RequestId string `json:"request_id,omitempty"`
			Output    struct {
				TaskId        string `json:"task_id,omitempty"`
				TaskStatus    string `json:"task_status,omitempty"`
				SubmitTime    string `json:"submit_time,omitempty"`
				ScheduledTime string `json:"scheduled_time,omitempty"`
				EndTime       string `json:"end_time,omitempty"`
				Results       []struct {
					OrigPrompt string `json:"orig_prompt,omitempty"`
					URL        string `json:"url,omitempty"`
					Code       string `json:"code,omitempty"`
					Message    string `json:"message,omitempty"`
				} `json:"results,omitempty"`
				TaskMetrics struct {
					Total     int `json:"TOTAL,omitempty"`
					Succeeded int `json:"SUCCEEDED,omitempty"`
					Failed    int `json:"FAILED,omitempty"`
				} `json:"task_metrics,omitempty"`
				Code    string `json:"code,omitempty"`
				Message string `json:"message,omitempty"`
			} `json:"output,omitempty"`
			Usage struct {
				ImageCount int `json:"image_count,omitempty"`
			} `json:"usage,omitempty"`
			Code    string `json:"code,omitempty"`
			Message string `json:"message,omitempty"`
		}

		if err := json.Unmarshal(body, &aliResponse); err != nil {
			return openai.ErrorWrapper(
				fmt.Errorf("failed to unmarshal ali response body: %v", err),
				"api_error",
				http.StatusInternalServerError,
			)
		}

		// å¤„ç†å„ç§å“åº”æƒ…å†µ
		switch aliResponse.Output.TaskStatus {
		case "SUCCEEDED":
			// ä»»åŠ¡æˆåŠŸï¼Œä½†éœ€è¦æ£€æŸ¥resultsä¸­æ˜¯å¦æœ‰å®é™…çš„å›¾ç‰‡
			var imageUrls []string
			var failedCount int
			var successCount int

			for _, result := range aliResponse.Output.Results {
				if result.URL != "" {
					// æˆåŠŸçš„å›¾ç‰‡
					imageUrls = append(imageUrls, result.URL)
					successCount++
				} else if result.Code != "" {
					// å¤±è´¥çš„å›¾ç‰‡
					failedCount++
				}
			}

			if len(imageUrls) > 0 {
				// æœ‰æˆåŠŸçš„å›¾ç‰‡
				finalResponse.TaskStatus = "succeed"
				finalResponse.ImageUrls = imageUrls
				finalResponse.ImageId = aliResponse.Output.TaskId

				if failedCount > 0 {
					finalResponse.Message = fmt.Sprintf("Partially completed: %d succeeded, %d failed", successCount, failedCount)
				} else {
					finalResponse.Message = "Image generation completed successfully"
				}
			} else {
				// æ²¡æœ‰ä»APIå“åº”ä¸­è·å–åˆ°URLï¼Œæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰å­˜å‚¨çš„URL
				if image.Status == "succeeded" && image.StoreUrl != "" {
					// å°è¯•ä»æ•°æ®åº“çš„storeUrlå­—æ®µè§£æURL
					var storedUrls []string
					if err := json.Unmarshal([]byte(image.StoreUrl), &storedUrls); err == nil && len(storedUrls) > 0 {
						// æˆåŠŸè§£æJSONæ ¼å¼çš„URLæ•°ç»„
						finalResponse.TaskStatus = "succeed"
						finalResponse.ImageUrls = storedUrls
						finalResponse.ImageId = aliResponse.Output.TaskId
						finalResponse.Message = "Image generation completed successfully"
					} else if image.StoreUrl != "" {
						// å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä½œä¸ºå•ä¸ªURLå¤„ç†
						finalResponse.TaskStatus = "succeed"
						finalResponse.ImageUrls = []string{image.StoreUrl}
						finalResponse.ImageId = aliResponse.Output.TaskId
						finalResponse.Message = "Image generation completed successfully"
					} else {
						// æ•°æ®åº“ä¸­ä¹Ÿæ²¡æœ‰æœ‰æ•ˆçš„URLï¼Œæ ‡è®°ä¸ºå¤±è´¥
						finalResponse.TaskStatus = "failed"
						finalResponse.Message = "No image URLs available"
					}
				} else {
					// æ²¡æœ‰æˆåŠŸçš„å›¾ç‰‡ï¼Œå…¨éƒ¨å¤±è´¥
					finalResponse.TaskStatus = "failed"
					if len(aliResponse.Output.Results) > 0 && aliResponse.Output.Results[0].Message != "" {
						finalResponse.Message = aliResponse.Output.Results[0].Message
					} else {
						finalResponse.Message = "All image generation tasks failed"
					}
				}
			}

		case "FAILED":
			// ä»»åŠ¡å®Œå…¨å¤±è´¥
			finalResponse.TaskStatus = "failed"
			if aliResponse.Output.Message != "" {
				finalResponse.Message = aliResponse.Output.Message
			} else {
				finalResponse.Message = "Image generation failed"
			}

		case "UNKNOWN":
			// ä»»åŠ¡è¿‡æœŸæˆ–ä¸å­˜åœ¨
			finalResponse.TaskStatus = "failed"
			finalResponse.Message = "Task expired or not found"

		case "PENDING", "RUNNING":
			// ä»»åŠ¡å¤„ç†ä¸­
			finalResponse.TaskStatus = "processing"
			if aliResponse.Output.TaskStatus == "PENDING" {
				finalResponse.Message = "Task is pending in queue"
			} else {
				finalResponse.Message = "Task is running, please check later"
			}

		case "CANCELED":
			// ä»»åŠ¡å·²å–æ¶ˆ
			finalResponse.TaskStatus = "failed"
			finalResponse.Message = "Task was canceled"

		default:
			// æœªçŸ¥çŠ¶æ€
			finalResponse.TaskStatus = "processing"
			finalResponse.Message = fmt.Sprintf("Unknown task status: %s", aliResponse.Output.TaskStatus)
		}

		// æ›´æ–°æ•°æ®åº“çŠ¶æ€ - ä¼ é€’åŸå§‹å“åº”ä½“è¿›è¡Œè§£æ
		updateAliImageTaskStatusFromBody(taskId, body, image)

	default:
		return openai.ErrorWrapper(
			fmt.Errorf("unsupported provider: %s", image.Provider),
			"unsupported_provider",
			http.StatusBadRequest,
		)
	}

	// Marshal and send the response
	responseJSON, err := json.Marshal(finalResponse)
	if err != nil {
		return openai.ErrorWrapper(
			fmt.Errorf("failed to marshal response: %v", err),
			"api_error",
			http.StatusInternalServerError,
		)
	}

	c.Writer.Header().Set("Content-Type", "application/json")
	c.Writer.WriteHeader(http.StatusOK)
	_, err = c.Writer.Write(responseJSON)
	if err != nil {
		return openai.ErrorWrapper(
			fmt.Errorf("failed to write response: %v", err),
			"api_error",
			http.StatusInternalServerError,
		)
	}

	return nil
}

// handleGeminiFormRequest å¤„ç† Gemini æ¨¡å‹çš„ form è¯·æ±‚ï¼Œè½¬æ¢ä¸º JSON æ ¼å¼
func handleGeminiFormRequest(c *gin.Context, ctx context.Context, imageRequest *relaymodel.ImageRequest, meta *util.RelayMeta, fullRequestURL string) *relaymodel.ErrorWithStatusCode {

	// è®°å½•å¼€å§‹æ—¶é—´ç”¨äºè®¡ç®—è€—æ—¶
	startTime := time.Now()

	// è®¡ç®—é…é¢ - å¯¹äº Gemini æ¨¡å‹éœ€è¦æ ¹æ®å®é™… token ä½¿ç”¨é‡è®¡ç®—ï¼Œè¿™é‡Œå…ˆç”¨ç”¨æˆ·é…ç½®çš„ä»·æ ¼
	modelPrice := common.GetModelPrice(imageRequest.Model, false)
	if modelPrice == -1 {
		modelPrice = 0.1 // é»˜è®¤ä»·æ ¼
	}

	groupRatio := common.GetGroupRatio(meta.Group)
	quota := int64(modelPrice*500000*groupRatio) * int64(imageRequest.N)

	// æ³¨æ„ï¼šGemini Form è¯·æ±‚çš„å®é™…é…é¢å°†åœ¨å“åº”å¤„ç†åæ ¹æ®çœŸå® token ä½¿ç”¨é‡æ–°è®¡ç®—

	// æ£€æŸ¥ç”¨æˆ·é…é¢æ˜¯å¦è¶³å¤Ÿ
	userQuota, err := model.CacheGetUserQuota(ctx, meta.UserId)
	if err != nil {
		return openai.ErrorWrapper(err, "failed to get user quota", http.StatusInternalServerError)
	}

	if userQuota-quota < 0 {
		return openai.ErrorWrapper(errors.New("user quota is not enough"), "insufficient_user_quota", http.StatusForbidden)
	}

	// ä» form ä¸­è·å– prompt
	prompt := ""
	if prompts, ok := c.Request.MultipartForm.Value["prompt"]; ok && len(prompts) > 0 {
		prompt = prompts[0]
	}
	if prompt == "" {
		return openai.ErrorWrapper(fmt.Errorf("prompt å­—æ®µä¸èƒ½ä¸ºç©º"), "missing_prompt", http.StatusBadRequest)
	}

	// ä» form ä¸­è·å–å›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªå›¾ç‰‡ï¼‰
	var imageParts []gemini.Part

	// æ”¯æŒä¸¤ç§å­—æ®µåæ ¼å¼ï¼šimage å’Œ image[]
	var fileHeaders []*multipart.FileHeader
	if headers, ok := c.Request.MultipartForm.File["image"]; ok && len(headers) > 0 {
		fileHeaders = headers
	} else if headers, ok := c.Request.MultipartForm.File["image[]"]; ok && len(headers) > 0 {
		fileHeaders = headers
	}

	if len(fileHeaders) > 0 {
		// éå†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
		for i, fileHeader := range fileHeaders {
			file, err := fileHeader.Open()
			if err != nil {
				return openai.ErrorWrapper(fmt.Errorf("open_image_file_%d_failed: %v", i+1, err), "open_image_file_failed", http.StatusBadRequest)
			}

			// ä½¿ç”¨åŒ¿åå‡½æ•°å’Œdeferç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
			fileErr := func() error {
				defer func() {
					if closeErr := file.Close(); closeErr != nil {
						logger.Warnf(ctx, "å…³é—­æ–‡ä»¶ %s å¤±è´¥: %v", fileHeader.Filename, closeErr)
					}
				}()

				// è¯»å–æ–‡ä»¶å†…å®¹
				fileBytes, err := io.ReadAll(file)
				if err != nil {
					return fmt.Errorf("read_image_file_%d_failed: %v", i+1, err)
				}

				// å°†æ–‡ä»¶å†…å®¹è½¬æ¢ä¸º base64
				imageBase64 := base64.StdEncoding.EncodeToString(fileBytes)

				// è·å– MIME ç±»å‹
				mimeType := fileHeader.Header.Get("Content-Type")
				if mimeType == "" || mimeType == "application/octet-stream" {
					// æ ¹æ®æ–‡ä»¶æ‰©å±•åæ¨æ–­ MIME ç±»å‹
					ext := strings.ToLower(filepath.Ext(fileHeader.Filename))
					switch ext {
					case ".png":
						mimeType = "image/png"
					case ".jpg", ".jpeg":
						mimeType = "image/jpeg"
					case ".webp":
						mimeType = "image/webp"
					case ".gif":
						mimeType = "image/gif"
					default:
						// é»˜è®¤ä¸º jpeg
						mimeType = "image/jpeg"
					}
				}

				// åˆ›å»ºå›¾ç‰‡éƒ¨åˆ†
				imagePart := gemini.Part{
					InlineData: &gemini.InlineData{
						MimeType: mimeType,
						Data:     imageBase64,
					},
				}
				imageParts = append(imageParts, imagePart)
				return nil
			}()

			// æ£€æŸ¥æ˜¯å¦æœ‰å¤„ç†é”™è¯¯
			if fileErr != nil {
				return openai.ErrorWrapper(fileErr, "read_image_file_failed", http.StatusBadRequest)
			}
		}
	} else {
		return openai.ErrorWrapper(fmt.Errorf("image æˆ– image[] æ–‡ä»¶ä¸èƒ½ä¸ºç©º"), "missing_image_file", http.StatusBadRequest)
	}

	// æ„å»º Gemini API è¯·æ±‚æ ¼å¼
	// æŒ‰ç…§é¡ºåºï¼šå…ˆæ·»åŠ æ‰€æœ‰å›¾ç‰‡ï¼Œæœ€åæ·»åŠ æ–‡æœ¬æç¤º
	var parts []gemini.Part

	// æ·»åŠ æ‰€æœ‰å›¾ç‰‡éƒ¨åˆ†
	parts = append(parts, imageParts...)

	// æœ€åæ·»åŠ æ–‡æœ¬æç¤º
	textPart := gemini.Part{
		Text: prompt,
	}
	parts = append(parts, textPart)

	geminiRequest := gemini.ChatRequest{
		Contents: []gemini.ChatContent{
			{
				Role:  "user",
				Parts: parts,
			},
		},
		GenerationConfig: gemini.ChatGenerationConfig{
			ResponseModalities: []string{"Image"},
		},
	}

	// å¤„ç† size å‚æ•°ï¼Œè½¬æ¢ä¸º Gemini çš„ aspectRatio
	if sizeValues, ok := c.Request.MultipartForm.Value["size"]; ok && len(sizeValues) > 0 {
		sizeStr := sizeValues[0]
		if sizeStr != "" {
			aspectRatio := convertSizeToAspectRatio(sizeStr)
			if aspectRatio != "" {
				// åªæœ‰æˆåŠŸè½¬æ¢æ‰è®¾ç½® ImageConfig
				geminiRequest.GenerationConfig.ImageConfig = &gemini.ImageConfig{
					AspectRatio: aspectRatio,
				}
				logger.Infof(ctx, "Gemini Form request: converted size '%s' to aspectRatio '%s'", sizeStr, aspectRatio)
			} else {
				// æ— æ³•è¯†åˆ«çš„æ ¼å¼ï¼Œä¸è®¾ç½® ImageConfigï¼Œä½¿ç”¨ Gemini é»˜è®¤è¡Œä¸º
				logger.Infof(ctx, "Gemini Form request: unrecognized size format '%s', using Gemini default behavior", sizeStr)
			}
		}
	}

	// è½¬æ¢ä¸º JSON
	jsonBytes, err := json.Marshal(geminiRequest)
	if err != nil {
		return openai.ErrorWrapper(err, "marshal_gemini_request_failed", http.StatusInternalServerError)
	}

	// æ›´æ–° URL ä¸º Gemini APIï¼ˆAPI key åº”è¯¥åœ¨ header ä¸­ï¼Œä¸æ˜¯ URL å‚æ•°ï¼‰
	// å¯¹äº Gemini APIï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨åŸå§‹æ¨¡å‹åç§°ï¼Œè€Œä¸æ˜¯æ˜ å°„åçš„åç§°
	if meta.ChannelType == common.ChannelTypeVertexAI {
		logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚å¤„ç† - å¼€å§‹æ„å»ºVertexAI URL")
		// ä¸ºVertexAIæ„å»ºURL
		keyIndex := 0
		if meta.KeyIndex != nil {
			keyIndex = *meta.KeyIndex
			logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - ä½¿ç”¨KeyIndex: %d", keyIndex)
		}

		// å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿keyIndexä¸ä¸ºè´Ÿæ•°
		if keyIndex < 0 {
			logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - keyIndexä¸ºè´Ÿæ•°: %dï¼Œé‡ç½®ä¸º0", keyIndex)
			keyIndex = 0
		}

		projectID := ""

		// å°è¯•ä»Keyå­—æ®µè§£æé¡¹ç›®IDï¼ˆæ”¯æŒå¤šå¯†é’¥ï¼‰
		if meta.IsMultiKey && len(meta.Keys) > keyIndex && keyIndex >= 0 {
			logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - å¤šå¯†é’¥æ¨¡å¼ï¼ŒKeysæ€»æ•°: %d", len(meta.Keys))
			// å¤šå¯†é’¥æ¨¡å¼ï¼šä»æŒ‡å®šç´¢å¼•çš„å¯†é’¥è§£æ
			var credentials vertexai.Credentials
			if err := json.Unmarshal([]byte(meta.Keys[keyIndex]), &credentials); err == nil {
				projectID = credentials.ProjectID
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - ä»å¤šå¯†é’¥è§£æProjectIDæˆåŠŸ: %s", projectID)
			} else {
				logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - ä»å¤šå¯†é’¥è§£æProjectIDå¤±è´¥: %v", err)
			}
		} else if meta.ActualAPIKey != "" {
			logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - å•å¯†é’¥æ¨¡å¼ï¼ŒActualAPIKeyé•¿åº¦: %d", len(meta.ActualAPIKey))
			// å•å¯†é’¥æ¨¡å¼ï¼šä»ActualAPIKeyè§£æ
			var credentials vertexai.Credentials
			if err := json.Unmarshal([]byte(meta.ActualAPIKey), &credentials); err == nil {
				projectID = credentials.ProjectID
				logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - ä»ActualAPIKeyè§£æProjectIDæˆåŠŸ: %s", projectID)
			} else {
				logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - ä»ActualAPIKeyè§£æProjectIDå¤±è´¥: %v", err)
			}
		} else {
			logger.Warnf(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - æ— æ³•è·å–å¯†é’¥ä¿¡æ¯")
		}

		// å›é€€ï¼šå°è¯•ä»Configè·å–é¡¹ç›®ID
		if projectID == "" && meta.Config.VertexAIProjectID != "" {
			projectID = meta.Config.VertexAIProjectID
			logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - ä»Configè·å–ProjectID: %s", projectID)
		}

		if projectID == "" {
			logger.Errorf(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - æ— æ³•è·å–ProjectID")
			return openai.ErrorWrapper(fmt.Errorf("VertexAI project ID not found"), "vertex_ai_project_id_missing", http.StatusBadRequest)
		}

		region := meta.Config.Region
		if region == "" {
			region = "global"
		}
		logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - ä½¿ç”¨Region: %s, Model: %s", region, meta.OriginModelName)

		// æ„å»ºVertexAI API URL - ä½¿ç”¨generateContentè€Œä¸æ˜¯predictç”¨äºå›¾åƒç”Ÿæˆ
		if region == "global" {
			fullRequestURL = fmt.Sprintf("https://aiplatform.googleapis.com/v1/projects/%s/locations/global/publishers/google/models/%s:generateContent", projectID, meta.OriginModelName)
		} else {
			fullRequestURL = fmt.Sprintf("https://%s-aiplatform.googleapis.com/v1/projects/%s/locations/%s/publishers/google/models/%s:generateContent", region, projectID, region, meta.OriginModelName)
		}
		logger.Infof(ctx, "ğŸ”§ [VertexAI Debug] Formè¯·æ±‚ - æ„å»ºçš„å®Œæ•´URL: %s", fullRequestURL)
	} else {
		// åŸæœ‰çš„Geminiå®˜æ–¹API URL
		fullRequestURL = fmt.Sprintf("%s/v1beta/models/%s:generateContent", meta.BaseURL, meta.OriginModelName)
	}

	// åˆ›å»ºè¯·æ±‚
	requestBuffer := bytes.NewBuffer(jsonBytes)
	req, err := http.NewRequest("POST", fullRequestURL, requestBuffer)
	if err != nil {
		return openai.ErrorWrapper(err, "new_request_failed", http.StatusInternalServerError)
	}

	// è®¾ç½®è¯·æ±‚å¤´
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Accept", "application/json")
	// æ³¨æ„ï¼šä¸æ‰‹åŠ¨è®¾ç½®Content-Lengthï¼Œè®©Goçš„http.Clientè‡ªåŠ¨è®¡ç®—
	logger.Debugf(ctx, "Gemini form-to-json body size: %d bytes", requestBuffer.Len())

	if meta.ChannelType == common.ChannelTypeVertexAI {
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] Formè¯·æ±‚ - å¼€å§‹VertexAIè®¤è¯æµç¨‹")
		// ä¸ºVertexAIä½¿ç”¨Bearer tokenè®¤è¯ - åˆ›å»ºæ–°çš„adaptorå®ä¾‹ï¼ˆFormè¯·æ±‚å¤„ç†æ—¶æ²¡æœ‰é¢„å…ˆåˆ›å»ºçš„adaptorï¼‰
		vertexAIAdaptor := &vertexai.Adaptor{}
		vertexAIAdaptor.Init(meta)

		logger.Infof(ctx, "ğŸ” [VertexAI Debug] Formè¯·æ±‚ - è°ƒç”¨GetAccessTokenè·å–è®¿é—®ä»¤ç‰Œ")
		accessToken, err := vertexai.GetAccessToken(vertexAIAdaptor, meta)
		if err != nil {
			logger.Errorf(ctx, "ğŸ” [VertexAI Debug] Formè¯·æ±‚ - è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: %v", err)
			return openai.ErrorWrapper(fmt.Errorf("failed to get VertexAI access token: %v", err), "vertex_ai_auth_failed", http.StatusUnauthorized)
		}

		// åªæ˜¾ç¤ºä»¤ç‰Œçš„å‰10ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•ï¼Œé¿å…å®Œæ•´ä»¤ç‰Œæ³„éœ²
		tokenPreview := ""
		if len(accessToken) > 10 {
			tokenPreview = accessToken[:10] + "..."
		} else {
			tokenPreview = accessToken
		}
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] Formè¯·æ±‚ - æˆåŠŸè·å–è®¿é—®ä»¤ç‰Œï¼Œé•¿åº¦: %d, å‰ç¼€: %s", len(accessToken), tokenPreview)

		req.Header.Set("Authorization", "Bearer "+accessToken)
		logger.Infof(ctx, "ğŸ” [VertexAI Debug] Formè¯·æ±‚ - å·²è®¾ç½®Authorization headerä¸ºBearer token")
	} else {
		// Gemini API æ­£ç¡®çš„ header æ ¼å¼
		req.Header.Set("x-goog-api-key", meta.APIKey)
	}

	// å‘é€è¯·æ±‚
	resp, err := util.HTTPClient.Do(req)
	if err != nil {
		return openai.ErrorWrapper(err, "do_request_failed", http.StatusInternalServerError)
	}
	defer resp.Body.Close()

	// å¤„ç†å“åº”
	return handleGeminiResponse(c, ctx, resp, imageRequest, meta, quota, startTime)
}

// handleGeminiResponse å¤„ç† Gemini API çš„å“åº”
func handleGeminiResponse(c *gin.Context, ctx context.Context, resp *http.Response, imageRequest *relaymodel.ImageRequest, meta *util.RelayMeta, quota int64, startTime time.Time) *relaymodel.ErrorWithStatusCode {
	// è¯»å–å“åº”ä½“
	responseBody, err := io.ReadAll(resp.Body)
	if err != nil {
		return openai.ErrorWrapper(err, "read_response_body_failed", http.StatusInternalServerError)
	}

	// è®°å½•åŸå§‹å“åº”ï¼ˆçœç•¥å…·ä½“å†…å®¹ï¼Œé¿å… base64 æ•°æ®å ç”¨æ—¥å¿—ï¼‰
	logger.Infof(ctx, "Gemini Form API å“åº”å·²æ¥æ”¶ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)

	// æ£€æŸ¥HTTPçŠ¶æ€ç 
	if resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusCreated {
		logger.Errorf(ctx, "Gemini APIè¿”å›é”™è¯¯çŠ¶æ€ç : %d, å“åº”ä½“: %s", resp.StatusCode, string(responseBody))

		// å°è¯•è§£æé”™è¯¯å“åº”
		var geminiError struct {
			Error struct {
				Code    int                      `json:"code"`
				Message string                   `json:"message"`
				Status  string                   `json:"status"`
				Details []map[string]interface{} `json:"details,omitempty"`
			} `json:"error"`
		}

		if err := json.Unmarshal(responseBody, &geminiError); err == nil && geminiError.Error.Message != "" {
			// åŒ…å«åŸå§‹å“åº”ä½“ï¼Œè¿™æ ·é‡è¯•é€»è¾‘å¯ä»¥æ­£ç¡®è¯†åˆ« API key é”™è¯¯
			errorMsg := fmt.Errorf("APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : %dï¼Œå“åº”: %s", resp.StatusCode, string(responseBody))
			errorCode := "gemini_" + strings.ToLower(geminiError.Error.Status)
			statusCode := geminiError.Error.Code
			if statusCode == 0 {
				statusCode = http.StatusBadRequest
			}
			return openai.ErrorWrapper(errorMsg, errorCode, statusCode)
		}

		// ç›´æ¥ä½¿ç”¨åŸå§‹å“åº”ä½“ä½œä¸ºé”™è¯¯æ¶ˆæ¯ï¼Œè¿™æ ·é‡è¯•é€»è¾‘å¯ä»¥æ­£ç¡®è¯†åˆ« API key é”™è¯¯
		return openai.ErrorWrapper(
			fmt.Errorf("APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : %dï¼Œå“åº”: %s", resp.StatusCode, string(responseBody)),
			"gemini_api_error",
			resp.StatusCode,
		)
	}

	// è§£æ Gemini æˆåŠŸå“åº”
	var geminiResponse struct {
		Candidates []struct {
			Content struct {
				Parts []struct {
					InlineData *gemini.InlineData `json:"inlineData,omitempty"`
					Text       string             `json:"text,omitempty"`
				} `json:"parts,omitempty"`
				Role string `json:"role,omitempty"`
			} `json:"content,omitempty"`
			FinishReason  string `json:"finishReason,omitempty"`
			FinishMessage string `json:"finishMessage,omitempty"`
			Index         int    `json:"index,omitempty"`
		} `json:"candidates,omitempty"`
		PromptFeedback *struct {
			BlockReason        string `json:"blockReason,omitempty"`
			BlockReasonMessage string `json:"blockReasonMessage,omitempty"`
		} `json:"promptFeedback,omitempty"`
		ModelVersion  string `json:"modelVersion,omitempty"`
		UsageMetadata struct {
			PromptTokenCount     int `json:"promptTokenCount,omitempty"`
			CandidatesTokenCount int `json:"candidatesTokenCount,omitempty"`
			TotalTokenCount      int `json:"totalTokenCount,omitempty"`
			PromptTokensDetails  []struct {
				Modality   string `json:"modality"`
				TokenCount int    `json:"tokenCount"`
			} `json:"promptTokensDetails,omitempty"`
			CandidatesTokensDetails []struct {
				Modality   string `json:"modality"`
				TokenCount int    `json:"tokenCount"`
			} `json:"candidatesTokensDetails,omitempty"`
		} `json:"usageMetadata,omitempty"`
	}

	err = json.Unmarshal(responseBody, &geminiResponse)
	if err != nil {
		logger.Errorf(ctx, "è§£æ Gemini æˆåŠŸå“åº”å¤±è´¥: %s", err.Error())
		return openai.ErrorWrapper(err, "unmarshal_gemini_response_failed", http.StatusInternalServerError)
	}

	// æ£€æŸ¥ promptFeedback æ˜¯å¦æœ‰é˜»æ­¢åŸå› 
	if geminiResponse.PromptFeedback != nil && geminiResponse.PromptFeedback.BlockReason != "" {
		var errorMessage string
		if geminiResponse.PromptFeedback.BlockReasonMessage != "" {
			errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: %s (åŸå› : %s)",
				geminiResponse.PromptFeedback.BlockReasonMessage,
				geminiResponse.PromptFeedback.BlockReason)
		} else {
			errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: æç¤ºè¯è¢«é˜»æ­¢ (åŸå› : %s)",
				geminiResponse.PromptFeedback.BlockReason)
		}

		logger.Errorf(ctx, "Gemini API promptFeedback é˜»æ­¢: BlockReason=%s, Message=%s",
			geminiResponse.PromptFeedback.BlockReason,
			geminiResponse.PromptFeedback.BlockReasonMessage)

		// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•
		responseStr := string(responseBody)
		if len(responseStr) > 1000 {
			responseStr = responseStr[:1000] + "...[truncated]"
		}
		logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

		// æ„å»ºåŒ…å«é”™è¯¯å’Œusageä¿¡æ¯çš„å“åº”
		errorResponse := map[string]interface{}{
			"error": map[string]interface{}{
				"code":    "gemini_prompt_blocked",
				"message": errorMessage,
				"param":   "",
				"type":    "api_error",
			},
			"created": time.Now().Unix(),
			"data":    nil,
			"usage": map[string]interface{}{
				"total_tokens":  geminiResponse.UsageMetadata.TotalTokenCount,
				"input_tokens":  geminiResponse.UsageMetadata.PromptTokenCount,
				"output_tokens": geminiResponse.UsageMetadata.CandidatesTokenCount,
				"input_tokens_details": map[string]int{
					"text_tokens":  0,
					"image_tokens": 0,
				},
			},
		}

		// ç›´æ¥è¿”å›å“åº”
		c.JSON(http.StatusBadRequest, errorResponse)

		// è®¡ç®—è¯·æ±‚è€—æ—¶
		rowDuration := time.Since(startTime).Seconds()
		duration := math.Round(rowDuration*1000) / 1000

		// å¤„ç†é…é¢æ¶ˆè´¹
		groupRatio := common.GetGroupRatio(meta.Group)
		promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
		completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

		modelRatio := common.GetModelRatio(meta.OriginModelName)
		completionRatio := common.GetCompletionRatio(meta.OriginModelName)
		actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

		logger.Infof(ctx, "Gemini Form promptFeedback é˜»æ­¢å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
			promptTokens, completionTokens, groupRatio, actualQuota, duration)

		// æ¶ˆè´¹é…é¢
		err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
		if err != nil {
			logger.SysError("error consuming token remain quota: " + err.Error())
		}

		err = model.CacheUpdateUserQuota(ctx, meta.UserId)
		if err != nil {
			logger.SysError("error update user quota cache: " + err.Error())
		}

		// è®°å½•æ¶ˆè´¹æ—¥å¿—
		referer := c.Request.Header.Get("HTTP-Referer")
		title := c.Request.Header.Get("X-Title")
		tokenName := c.GetString("token_name")
		xRequestID := c.GetString("X-Request-ID")

		logContent := fmt.Sprintf("Gemini Form Prompt Blocked - Model: %s, BlockReason: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
			meta.OriginModelName, geminiResponse.PromptFeedback.BlockReason, promptTokens, completionTokens, actualQuota, duration)

		// è·å–æ¸ é“å†å²ä¿¡æ¯
		var otherInfo string
		if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
			if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
				if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
					otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
				}
			}
		}

		// è®°å½•æ—¥å¿—
		model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
			tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

		model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
		channelId := c.GetInt("channel_id")
		model.UpdateChannelUsedQuota(channelId, actualQuota)

		return nil
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰é¡¹
	if len(geminiResponse.Candidates) == 0 {
		logger.Errorf(ctx, "Gemini API æœªè¿”å›ä»»ä½•å€™é€‰é¡¹")
		// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
		responseStr := string(responseBody)
		if len(responseStr) > 1000 {
			responseStr = responseStr[:1000] + "...[truncated]"
		}
		logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

		// è®°å½•æ¶ˆè´¹æ—¥å¿—ï¼ˆå³ä½¿æ²¡æœ‰å€™é€‰é¡¹ï¼Œä¹Ÿè¦è®°å½•è¯·æ±‚æ¶ˆè€—ï¼‰
		rowDuration := time.Since(startTime).Seconds()
		duration := math.Round(rowDuration*1000) / 1000

		groupRatio := common.GetGroupRatio(meta.Group)
		promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
		completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

		modelRatio := common.GetModelRatio(meta.OriginModelName)
		completionRatio := common.GetCompletionRatio(meta.OriginModelName)
		actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

		logger.Infof(ctx, "Gemini JSON ç©ºå€™é€‰é¡¹å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
			promptTokens, completionTokens, groupRatio, actualQuota, duration)

		// æ¶ˆè´¹é…é¢
		err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
		if err != nil {
			logger.SysError("error consuming token remain quota: " + err.Error())
		}

		err = model.CacheUpdateUserQuota(ctx, meta.UserId)
		if err != nil {
			logger.SysError("error update user quota cache: " + err.Error())
		}

		// è®°å½•æ¶ˆè´¹æ—¥å¿—
		referer := c.Request.Header.Get("HTTP-Referer")
		title := c.Request.Header.Get("X-Title")
		tokenName := c.GetString("token_name")
		xRequestID := c.GetString("X-Request-ID")

		logContent := fmt.Sprintf("Gemini JSON No Candidates - Model: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
			meta.OriginModelName, promptTokens, completionTokens, actualQuota, duration)

		// è·å–æ¸ é“å†å²ä¿¡æ¯
		var otherInfo string
		if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
			if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
				if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
					otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
				}
			}
		}

		// è®°å½•æ—¥å¿—
		model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
			tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

		model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
		channelId := c.GetInt("channel_id")
		model.UpdateChannelUsedQuota(channelId, actualQuota)

		return openai.ErrorWrapper(
			fmt.Errorf("Gemini API é”™è¯¯: æœªè¿”å›ä»»ä½•å€™é€‰é¡¹"),
			"gemini_no_candidates",
			http.StatusBadRequest,
		)
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰éæ­£å¸¸å®Œæˆçš„å€™é€‰é¡¹
	for _, candidate := range geminiResponse.Candidates {
		if candidate.FinishReason != "" && candidate.FinishReason != "STOP" {
			// æ„å»ºé”™è¯¯æ¶ˆæ¯ï¼Œä¼˜å…ˆä½¿ç”¨ finishMessage
			var errorMessage string
			if candidate.FinishMessage != "" {
				errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: %s (åŸå› : %s)", candidate.FinishMessage, candidate.FinishReason)
				logger.Errorf(ctx, "Gemini API è¿”å›éæ­£å¸¸å®Œæˆ: FinishReason=%s, FinishMessage=%s", candidate.FinishReason, candidate.FinishMessage)
			} else {
				errorMessage = fmt.Sprintf("Gemini API é”™è¯¯: ç”Ÿæˆæœªæ­£å¸¸å®Œæˆ (åŸå› : %s)", candidate.FinishReason)
				logger.Errorf(ctx, "Gemini API è¿”å›éæ­£å¸¸å®ŒæˆåŸå› : %s", candidate.FinishReason)
			}

			// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
			responseStr := string(responseBody)
			if len(responseStr) > 1000 {
				responseStr = responseStr[:1000] + "...[truncated]"
			}
			logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

			// æ„å»ºåŒ…å«é”™è¯¯å’Œusageä¿¡æ¯çš„å“åº”
			errorResponse := map[string]interface{}{
				"error": map[string]interface{}{
					"code":    "gemini_incomplete_generation",
					"message": errorMessage,
					"param":   "",
					"type":    "api_error",
				},
				"created": time.Now().Unix(),
				"data":    nil,
				"usage": map[string]interface{}{
					"total_tokens":  geminiResponse.UsageMetadata.TotalTokenCount,
					"input_tokens":  geminiResponse.UsageMetadata.PromptTokenCount,
					"output_tokens": geminiResponse.UsageMetadata.CandidatesTokenCount,
					"input_tokens_details": map[string]int{
						"text_tokens":  0,
						"image_tokens": 0,
					},
				},
			}

			// ç›´æ¥è¿”å›å“åº”
			c.JSON(http.StatusBadRequest, errorResponse)

			// è®¡ç®—è¯·æ±‚è€—æ—¶
			rowDuration := time.Since(startTime).Seconds()
			duration := math.Round(rowDuration*1000) / 1000

			// å¤„ç†é…é¢æ¶ˆè´¹ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ‰£è´¹ï¼Œå› ä¸ºå·²ç»æ¶ˆè€—äº†tokenï¼‰
			groupRatio := common.GetGroupRatio(meta.Group)
			promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
			completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

			modelRatio := common.GetModelRatio(meta.OriginModelName)
			completionRatio := common.GetCompletionRatio(meta.OriginModelName)
			actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

			logger.Infof(ctx, "Gemini Form é”™è¯¯å“åº”å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
				promptTokens, completionTokens, groupRatio, actualQuota, duration)

			// æ¶ˆè´¹é…é¢
			err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
			if err != nil {
				logger.SysError("error consuming token remain quota: " + err.Error())
			}

			err = model.CacheUpdateUserQuota(ctx, meta.UserId)
			if err != nil {
				logger.SysError("error update user quota cache: " + err.Error())
			}

			// è®°å½•æ¶ˆè´¹æ—¥å¿—
			referer := c.Request.Header.Get("HTTP-Referer")
			title := c.Request.Header.Get("X-Title")
			tokenName := c.GetString("token_name")
			xRequestID := c.GetString("X-Request-ID")

			logContent := fmt.Sprintf("Gemini Form Error - Model: %s, FinishReason: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
				meta.OriginModelName, candidate.FinishReason, promptTokens, completionTokens, actualQuota, duration)

			// è·å–æ¸ é“å†å²ä¿¡æ¯
			var otherInfo string
			if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
				if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
					if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
						otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
					}
				}
			}

			// è®°å½•æ—¥å¿—
			model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
				tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

			model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
			channelId := c.GetInt("channel_id")
			model.UpdateChannelUsedQuota(channelId, actualQuota)

			return nil
		}
	}

	// è½¬æ¢ä¸º OpenAI DALL-E å…¼å®¹æ ¼å¼
	var imageData []struct {
		B64Json string `json:"b64_json"`
	}

	// ä» Gemini å“åº”ä¸­æå–å›¾åƒæ•°æ®
	for i, candidate := range geminiResponse.Candidates {
		for j, part := range candidate.Content.Parts {
			if part.InlineData != nil {
				// ä½¿ç”¨ b64_json å­—æ®µï¼ˆOpenAI æ ‡å‡†ï¼‰
				imageData = append(imageData, struct {
					B64Json string `json:"b64_json"`
				}{
					B64Json: part.InlineData.Data,
				})
			} else if part.Text != "" {
				logger.Infof(ctx, "å€™é€‰é¡¹ #%d éƒ¨åˆ† #%d åŒ…å«æ–‡æœ¬: %s", i, j, part.Text)
			}
		}
	}

	// æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›é”™è¯¯
	if len(imageData) == 0 {
		// è¯¦ç»†åˆ†ææ— å›¾ç‰‡çš„åŸå› 
		var detailReason string
		if len(geminiResponse.Candidates) == 0 {
			detailReason = "candidates æ•°ç»„ä¸ºç©º"
		} else if len(geminiResponse.Candidates[0].Content.Parts) == 0 {
			detailReason = "content.parts æ•°ç»„ä¸ºç©º"
		} else {
			hasText := false
			hasEmptyPart := false
			for _, part := range geminiResponse.Candidates[0].Content.Parts {
				if part.Text != "" {
					hasText = true
				}
				if part.InlineData == nil && part.Text == "" {
					hasEmptyPart = true
				}
			}
			if hasText {
				detailReason = "åªåŒ…å«æ–‡æœ¬ï¼Œæ²¡æœ‰å›¾ç‰‡æ•°æ®"
			} else if hasEmptyPart {
				detailReason = "parts åŒ…å«ç©ºå¯¹è±¡"
			} else {
				detailReason = "æœªçŸ¥åŸå› "
			}
		}
		
		logger.Errorf(ctx, "Gemini API æœªè¿”å›å›¾ç‰‡æ•°æ®: %s", detailReason)

		// æ‰“å°åŸå§‹å“åº”ä½“ç”¨äºè°ƒè¯•ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
		responseStr := string(responseBody)
		if len(responseStr) > 1000 {
			responseStr = responseStr[:1000] + "...[truncated]"
		}
		logger.Errorf(ctx, "Gemini åŸå§‹å“åº”ä½“: %s", responseStr)

		// æ„å»ºåŒ…å«é”™è¯¯å’Œusageä¿¡æ¯çš„å“åº”
		errorResponse := map[string]interface{}{
			"error": map[string]interface{}{
				"code":    "gemini_no_image_generated",
				"message": "Gemini API é”™è¯¯: æœªç”Ÿæˆå›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æç¤ºè¯æˆ–é‡è¯•",
				"param":   "",
				"type":    "api_error",
			},
			"created": time.Now().Unix(),
			"data":    nil,
			"usage": map[string]interface{}{
				"total_tokens":  geminiResponse.UsageMetadata.TotalTokenCount,
				"input_tokens":  geminiResponse.UsageMetadata.PromptTokenCount,
				"output_tokens": geminiResponse.UsageMetadata.CandidatesTokenCount,
				"input_tokens_details": map[string]int{
					"text_tokens":  0,
					"image_tokens": 0,
				},
			},
		}

		// ç›´æ¥è¿”å›å“åº”
		c.JSON(http.StatusBadRequest, errorResponse)

		// è®¡ç®—è¯·æ±‚è€—æ—¶
		rowDuration := time.Since(startTime).Seconds()
		duration := math.Round(rowDuration*1000) / 1000

		// å¤„ç†é…é¢æ¶ˆè´¹ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ‰£è´¹ï¼Œå› ä¸ºå·²ç»æ¶ˆè€—äº†tokenï¼‰
		groupRatio := common.GetGroupRatio(meta.Group)
		promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
		completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

		modelRatio := common.GetModelRatio(meta.OriginModelName)
		completionRatio := common.GetCompletionRatio(meta.OriginModelName)
		actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

		logger.Infof(ctx, "Gemini Form æ— å›¾ç‰‡å“åº”å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
			promptTokens, completionTokens, groupRatio, actualQuota, duration)

		// æ¶ˆè´¹é…é¢
		err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
		if err != nil {
			logger.SysError("error consuming token remain quota: " + err.Error())
		}

		err = model.CacheUpdateUserQuota(ctx, meta.UserId)
		if err != nil {
			logger.SysError("error update user quota cache: " + err.Error())
		}

		// è®°å½•æ¶ˆè´¹æ—¥å¿—
		referer := c.Request.Header.Get("HTTP-Referer")
		title := c.Request.Header.Get("X-Title")
		tokenName := c.GetString("token_name")
		xRequestID := c.GetString("X-Request-ID")

		logContent := fmt.Sprintf("Gemini Form No Image - Model: %s, è¾“å…¥: %d tokens, è¾“å‡º: %d tokens, é…é¢: %d, è€—æ—¶: %.3fs",
			meta.OriginModelName, promptTokens, completionTokens, actualQuota, duration)

		// è·å–æ¸ é“å†å²ä¿¡æ¯
		var otherInfo string
		if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
			if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
				if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
					otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
				}
			}
		}

		// è®°å½•æ—¥å¿—
		model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName,
			tokenName, actualQuota, logContent, duration, title, referer, false, 0, otherInfo, xRequestID)

		model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
		channelId := c.GetInt("channel_id")
		model.UpdateChannelUsedQuota(channelId, actualQuota)

		return nil
	}

	// åˆ›å»ºå…¼å®¹ OpenAI æ ¼å¼çš„å“åº”æ•°æ®
	var openaiCompatibleData []struct {
		Url     string `json:"url,omitempty"`
		B64Json string `json:"b64_json,omitempty"`
	}
	for _, img := range imageData {
		openaiCompatibleData = append(openaiCompatibleData, struct {
			Url     string `json:"url,omitempty"`
			B64Json string `json:"b64_json,omitempty"`
		}{
			B64Json: img.B64Json,
		})
	}

	// æ„å»ºåŒ…å«å®Œæ•´ usage ä¿¡æ¯çš„å“åº”ç»“æ„ä½“
	type ImageResponseWithUsage struct {
		Created int `json:"created"`
		Data    []struct {
			Url     string `json:"url,omitempty"`
			B64Json string `json:"b64_json,omitempty"`
		} `json:"data"`
		Usage struct {
			TotalTokens        int `json:"total_tokens"`
			InputTokens        int `json:"input_tokens"`
			OutputTokens       int `json:"output_tokens"`
			InputTokensDetails struct {
				TextTokens  int `json:"text_tokens"`
				ImageTokens int `json:"image_tokens"`
			} `json:"input_tokens_details"`
		} `json:"usage,omitempty"`
	}

	// æ„å»ºæœ€ç»ˆå“åº”
	imageResponse := ImageResponseWithUsage{
		Created: int(time.Now().Unix()),
		Data:    openaiCompatibleData,
		Usage: struct {
			TotalTokens        int `json:"total_tokens"`
			InputTokens        int `json:"input_tokens"`
			OutputTokens       int `json:"output_tokens"`
			InputTokensDetails struct {
				TextTokens  int `json:"text_tokens"`
				ImageTokens int `json:"image_tokens"`
			} `json:"input_tokens_details"`
		}{
			TotalTokens:  geminiResponse.UsageMetadata.TotalTokenCount,
			InputTokens:  geminiResponse.UsageMetadata.PromptTokenCount,
			OutputTokens: geminiResponse.UsageMetadata.CandidatesTokenCount,
			InputTokensDetails: struct {
				TextTokens  int `json:"text_tokens"`
				ImageTokens int `json:"image_tokens"`
			}{
				// Gemini ä¸æä¾›è¯¦ç»†çš„ token åˆ†è§£ï¼Œè®¾ä¸º 0
				TextTokens:  0,
				ImageTokens: 0,
			},
		},
	}

	// é‡æ–°åºåˆ—åŒ–ä¸º OpenAI æ ¼å¼
	finalResponseBody, err := json.Marshal(imageResponse)
	if err != nil {
		logger.Errorf(ctx, "åºåˆ—åŒ–è½¬æ¢åçš„å“åº”å¤±è´¥: %s", err.Error())
		return openai.ErrorWrapper(err, "marshal_converted_response_failed", http.StatusInternalServerError)
	}

	// è®°å½• usage ä¿¡æ¯
	logger.Infof(ctx, "Gemini Form å“åº”åŒ…å« usage ä¿¡æ¯: total_tokens=%d, input_tokens=%d, output_tokens=%d, text_tokens=%d, image_tokens=%d",
		imageResponse.Usage.TotalTokens,
		imageResponse.Usage.InputTokens,
		imageResponse.Usage.OutputTokens,
		0, // Gemini ä¸æä¾›è¯¦ç»†åˆ†è§£
		0) // Gemini ä¸æä¾›è¯¦ç»†åˆ†è§£

	// æ³¨æ„ï¼šä¸æ‰‹åŠ¨è®¾ç½®Content-Lengthï¼Œè®©Ginçš„c.JSON()è‡ªåŠ¨å¤„ç†
	// è®°å½•å“åº”ä½“å¤§å°ç”¨äºè°ƒè¯•
	logger.Debugf(ctx, "Gemini form response body size: %d bytes", len(finalResponseBody))

	// ä½¿ç”¨c.Data()è®©Ginè‡ªåŠ¨å¤„ç†Content-Length
	c.Data(http.StatusOK, "application/json", finalResponseBody)

	// è®¡ç®—è¯·æ±‚è€—æ—¶
	rowDuration := time.Since(startTime).Seconds()
	duration := math.Round(rowDuration*1000) / 1000

	// ä½¿ç”¨ç»Ÿä¸€çš„ModelRatioå’ŒCompletionRatioæœºåˆ¶è¿›è¡Œè®¡è´¹
	groupRatio := common.GetGroupRatio(meta.Group)
	promptTokens := geminiResponse.UsageMetadata.PromptTokenCount
	completionTokens := geminiResponse.UsageMetadata.CandidatesTokenCount

	modelRatio := common.GetModelRatio(meta.OriginModelName)
	completionRatio := common.GetCompletionRatio(meta.OriginModelName)
	actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

	logger.Infof(ctx, "Gemini Form å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
		promptTokens, completionTokens, groupRatio, actualQuota, duration)

	// å¤„ç†é…é¢æ¶ˆè´¹ï¼ˆä½¿ç”¨é‡æ–°è®¡ç®—çš„é…é¢ï¼‰
	err = model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
	if err != nil {
		logger.SysError("error consuming token remain quota: " + err.Error())
	}

	err = model.CacheUpdateUserQuota(ctx, meta.UserId)
	if err != nil {
		logger.SysError("error update user quota cache: " + err.Error())
	}

	// è®°å½•æ¶ˆè´¹æ—¥å¿—
	referer := c.Request.Header.Get("HTTP-Referer")
	title := c.Request.Header.Get("X-Title")
	tokenName := c.GetString("token_name")
	xRequestID := c.GetString("X-Request-ID")

	// è®¡ç®—è¯¦ç»†çš„æˆæœ¬ä¿¡æ¯
	inputCost := float64(promptTokens) / 1000000.0 * 0.3
	outputCost := float64(completionTokens) / 1000000.0 * 30.0
	totalCost := inputCost + outputCost

	logContent := fmt.Sprintf("Gemini Form Request - Model: %s, è¾“å…¥æˆæœ¬: $%.6f (%d tokens), è¾“å‡ºæˆæœ¬: $%.6f (%d tokens), æ€»æˆæœ¬: $%.6f, åˆ†ç»„å€ç‡: %.2f, é…é¢: %d, è€—æ—¶: %.3fs",
		meta.OriginModelName, inputCost, promptTokens, outputCost, completionTokens, totalCost, groupRatio, actualQuota, duration)

	// è®°å½•è¯¦ç»†çš„ token ä½¿ç”¨æƒ…å†µ
	logger.Infof(ctx, "Gemini Form Token Usage - Prompt: %d, Candidates: %d, Total: %d, Duration: %.3fs",
		promptTokens, completionTokens, geminiResponse.UsageMetadata.TotalTokenCount, duration)

	// è·å–æ¸ é“å†å²ä¿¡æ¯å¹¶è®°å½•æ—¥å¿—
	var otherInfo string
	if channelHistoryInterface, exists := c.Get("admin_channel_history"); exists {
		if channelHistory, ok := channelHistoryInterface.([]int); ok && len(channelHistory) > 0 {
			if channelHistoryBytes, err := json.Marshal(channelHistory); err == nil {
				otherInfo = fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
			}
		}
	}

	if otherInfo != "" {
		model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName, tokenName, actualQuota, logContent, duration, title, referer, false, 0.0, otherInfo, xRequestID)
	} else {
		model.RecordConsumeLogWithRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName, tokenName, actualQuota, logContent, duration, title, referer, false, 0.0, xRequestID)
	}
	model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
	channelId := c.GetInt("channel_id")
	model.UpdateChannelUsedQuota(channelId, actualQuota)

	return nil
}

// handleGeminiTokenConsumption å¤„ç† Gemini JSON è¯·æ±‚çš„ token æ¶ˆè´¹å’Œæ—¥å¿—è®°å½•
func handleGeminiTokenConsumption(c *gin.Context, ctx context.Context, meta *util.RelayMeta, imageRequest *relaymodel.ImageRequest, geminiResponse interface{}, quota int64, startTime time.Time) error {
	// æ£€æŸ¥æ˜¯å¦å·²ç»è®°å½•è¿‡ï¼ˆé€šè¿‡æ£€æŸ¥æ˜¯å¦å·²ç»è®¾ç½®äº†å“åº”çŠ¶æ€ç ï¼‰
	if c.Writer.Status() == http.StatusBadRequest {
		logger.Infof(ctx, "Gemini è¯·æ±‚å·²åœ¨é”™è¯¯å¤„ç†ä¸­è®°å½•æ¶ˆè´¹æ—¥å¿—ï¼Œè·³è¿‡é‡å¤å¤„ç†")
		return nil
	}

	// è®¡ç®—è¯·æ±‚è€—æ—¶
	rowDuration := time.Since(startTime).Seconds()
	duration := math.Round(rowDuration*1000) / 1000

	// ä» geminiResponse ä¸­æå– token ä¿¡æ¯
	var promptTokens, completionTokens int

	// ä½¿ç”¨ç±»å‹æ–­è¨€æ¥è·å– UsageMetadata
	if respStruct, ok := geminiResponse.(*struct {
		Candidates []struct {
			Content struct {
				Parts []struct {
					InlineData *gemini.InlineData `json:"inlineData,omitempty"`
					Text       string             `json:"text,omitempty"`
				} `json:"parts,omitempty"`
				Role string `json:"role,omitempty"`
			} `json:"content,omitempty"`
			FinishReason  string `json:"finishReason,omitempty"`
			FinishMessage string `json:"finishMessage,omitempty"`
			Index         int    `json:"index,omitempty"`
		} `json:"candidates,omitempty"`
		PromptFeedback *struct {
			BlockReason        string `json:"blockReason,omitempty"`
			BlockReasonMessage string `json:"blockReasonMessage,omitempty"`
		} `json:"promptFeedback,omitempty"`
		ModelVersion  string `json:"modelVersion,omitempty"`
		UsageMetadata struct {
			PromptTokenCount     int `json:"promptTokenCount,omitempty"`
			CandidatesTokenCount int `json:"candidatesTokenCount,omitempty"`
			TotalTokenCount      int `json:"totalTokenCount,omitempty"`
		} `json:"usageMetadata,omitempty"`
	}); ok {
		// æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ UsageMetadata
		if respStruct.UsageMetadata.TotalTokenCount == 0 {
			logger.Warnf(ctx, "Gemini å“åº”ä¸­ UsageMetadata ä¸ºç©ºï¼Œå¯èƒ½å·²åœ¨é”™è¯¯å¤„ç†ä¸­è®°å½•")
			return nil
		}

		promptTokens = respStruct.UsageMetadata.PromptTokenCount
		completionTokens = respStruct.UsageMetadata.CandidatesTokenCount

		logger.Infof(ctx, "Gemini JSON æˆåŠŸå“åº”å¤„ç† token: prompt=%d, completion=%d, total=%d",
			promptTokens, completionTokens, respStruct.UsageMetadata.TotalTokenCount)
	} else {
		logger.Warnf(ctx, "æ— æ³•ä» Gemini å“åº”ä¸­æå– token ä¿¡æ¯ï¼ˆå¯èƒ½å·²åœ¨é”™è¯¯å¤„ç†ä¸­è®°å½•ï¼‰")
		return nil // ä¸è¿”å›é”™è¯¯ï¼Œé¿å…å½±å“æˆåŠŸå“åº”
	}

	// ä½¿ç”¨ç»Ÿä¸€çš„ModelRatioå’ŒCompletionRatioæœºåˆ¶è¿›è¡Œè®¡è´¹
	groupRatio := common.GetGroupRatio(meta.Group)
	modelRatio := common.GetModelRatio(meta.OriginModelName)
	completionRatio := common.GetCompletionRatio(meta.OriginModelName)
	// ä½¿ç”¨ç»Ÿä¸€çš„ ModelRatio å’Œ CompletionRatio æœºåˆ¶è¿›è¡Œè®¡è´¹
	// modelRatio å·²ç»æ˜¯ç›¸å¯¹äºåŸºç¡€ä»·æ ¼ $0.002/1K tokens çš„å€ç‡ï¼Œç›´æ¥ä½¿ç”¨å³å¯
	actualQuota := int64(math.Ceil((float64(promptTokens) + float64(completionTokens)*completionRatio) * modelRatio * groupRatio))

	logger.Infof(ctx, "Gemini JSON å®šä»·è®¡ç®—: è¾“å…¥=%d tokens, è¾“å‡º=%d tokens, åˆ†ç»„å€ç‡=%.2f, è®¡ç®—é…é¢=%d, è€—æ—¶=%.3fs",
		promptTokens, completionTokens, groupRatio, actualQuota, duration)

	// å¤„ç†é…é¢æ¶ˆè´¹ï¼ˆä½¿ç”¨é‡æ–°è®¡ç®—çš„é…é¢ï¼‰
	err := model.PostConsumeTokenQuota(meta.TokenId, actualQuota)
	if err != nil {
		logger.SysError("error consuming token remain quota: " + err.Error())
		return err
	}

	err = model.CacheUpdateUserQuota(ctx, meta.UserId)
	if err != nil {
		logger.SysError("error update user quota cache: " + err.Error())
		return err
	}

	// è®°å½•æ¶ˆè´¹æ—¥å¿—
	referer := c.Request.Header.Get("HTTP-Referer")
	title := c.Request.Header.Get("X-Title")
	tokenName := c.GetString("token_name")
	xRequestID := c.GetString("X-Request-ID")

	// è®¡ç®—è¯¦ç»†çš„æˆæœ¬ä¿¡æ¯
	inputCost := float64(promptTokens) / 1000000.0 * 0.3
	outputCost := float64(completionTokens) / 1000000.0 * 30.0
	totalCost := inputCost + outputCost

	logContent := fmt.Sprintf("Gemini JSON Request - Model: %s, è¾“å…¥æˆæœ¬: $%.6f (%d tokens), è¾“å‡ºæˆæœ¬: $%.6f (%d tokens), æ€»æˆæœ¬: $%.6f, åˆ†ç»„å€ç‡: %.2f, é…é¢: %d, è€—æ—¶: %.3fs",
		meta.OriginModelName, inputCost, promptTokens, outputCost, completionTokens, totalCost, groupRatio, actualQuota, duration)

	// è·å–æ¸ é“å†å²ä¿¡æ¯å¹¶è®°å½•æ—¥å¿—
	otherInfo := extractChannelHistoryInfo(ctx, c)

	if otherInfo != "" {
		model.RecordConsumeLogWithOtherAndRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName, tokenName, actualQuota, logContent, duration, title, referer, false, 0.0, otherInfo, xRequestID)
	} else {
		model.RecordConsumeLogWithRequestID(ctx, meta.UserId, meta.ChannelId, promptTokens, completionTokens, meta.OriginModelName, tokenName, actualQuota, logContent, duration, title, referer, false, 0.0, xRequestID)
	}
	model.UpdateUserUsedQuotaAndRequestCount(meta.UserId, actualQuota)
	channelId := c.GetInt("channel_id")
	model.UpdateChannelUsedQuota(channelId, actualQuota)

	logger.Infof(ctx, "Gemini JSON token consumption completed: prompt=%d, completion=%d, duration=%.3fs", promptTokens, completionTokens, duration)
	return nil
}

// extractChannelHistoryInfo ä»ginä¸Šä¸‹æ–‡ä¸­æå–æ¸ é“å†å²ä¿¡æ¯
func extractChannelHistoryInfo(ctx context.Context, c *gin.Context) string {
	channelHistoryInterface, exists := c.Get("admin_channel_history")
	if !exists {
		return ""
	}

	channelHistory, ok := channelHistoryInterface.([]int)
	if !ok || len(channelHistory) == 0 {
		logger.Debugf(ctx, "Invalid channel history type or empty: %T", channelHistoryInterface)
		return ""
	}

	channelHistoryBytes, err := json.Marshal(channelHistory)
	if err != nil {
		logger.Warnf(ctx, "Failed to marshal channel history %v: %v", channelHistory, err)
		return ""
	}

	return fmt.Sprintf("adminInfo:%s", string(channelHistoryBytes))
}

// extractImageInputs ä»interface{}ä¸­æå–å›¾ç‰‡è¾“å…¥åˆ—è¡¨
// æ”¯æŒå•ä¸ªå­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²æ•°ç»„
func extractImageInputs(value interface{}) []string {
	var inputs []string

	switch v := value.(type) {
	case string:
		// å•ä¸ªå­—ç¬¦ä¸²
		if v != "" {
			inputs = append(inputs, v)
		}
	case []interface{}:
		// æ•°ç»„å½¢å¼
		for _, item := range v {
			if str, ok := item.(string); ok && str != "" {
				inputs = append(inputs, str)
			}
		}
	case []string:
		// å­—ç¬¦ä¸²æ•°ç»„
		for _, str := range v {
			if str != "" {
				inputs = append(inputs, str)
			}
		}
	}

	return inputs
}

// parseImageInput è§£æå•ä¸ªå›¾ç‰‡è¾“å…¥ï¼ˆURLæˆ–base64æ•°æ®ï¼‰
func parseImageInput(ctx context.Context, input string) gemini.Part {
	// æ£€æŸ¥æ˜¯å¦æ˜¯base64æ ¼å¼çš„æ•°æ®URL
	if strings.HasPrefix(input, "data:") {
		// è§£ædata URLæ ¼å¼: data:image/png;base64,BASE64_DATA
		parts := strings.SplitN(input, ",", 2)

		var mimeType string
		var imageData string

		if len(parts) == 2 {
			// æå–MIMEç±»å‹
			mimeTypeParts := strings.SplitN(parts[0], ":", 2)
			if len(mimeTypeParts) == 2 {
				mimeTypeParts = strings.SplitN(mimeTypeParts[1], ";", 2)
				if len(mimeTypeParts) > 0 {
					mimeType = mimeTypeParts[0]
				}
			}
			imageData = parts[1]
		} else {
			// å¦‚æœæ²¡æœ‰æ‰¾åˆ°é€—å·ï¼Œé»˜è®¤ä¸ºPNGæ ¼å¼
			mimeType = "image/png"
			imageData = input[5:] // ç§»é™¤"data:"å‰ç¼€
		}

		return gemini.Part{
			InlineData: &gemini.InlineData{
				MimeType: mimeType,
				Data:     imageData,
			},
		}
	} else if strings.HasPrefix(input, "http://") || strings.HasPrefix(input, "https://") {
		// å¤„ç†URLæ ¼å¼çš„å›¾ç‰‡ï¼šä¸‹è½½å¹¶è½¬æ¢ä¸ºbase64
		logger.Infof(ctx, "Downloading image from URL: %s", input)

		imageData, mimeType, err := downloadImageToBase64(ctx, input)
		if err != nil {
			logger.Errorf(ctx, "Failed to download image from URL %s: %v", input, err)
			return gemini.Part{}
		}

		logger.Infof(ctx, "Successfully downloaded image from URL, MIME type: %s, size: %d bytes", mimeType, len(imageData))

		return gemini.Part{
			InlineData: &gemini.InlineData{
				MimeType: mimeType,
				Data:     imageData,
			},
		}
	} else {
		// å‡è®¾æ˜¯çº¯base64æ•°æ®ï¼ˆæ²¡æœ‰data URLå‰ç¼€ï¼‰
		return gemini.Part{
			InlineData: &gemini.InlineData{
				MimeType: "image/png", // é»˜è®¤PNGæ ¼å¼
				Data:     input,
			},
		}
	}
}

// downloadImageToBase64 ä»URLä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
func downloadImageToBase64(ctx context.Context, imageURL string) (base64Data string, mimeType string, err error) {
	// è®¾ç½®HTTPå®¢æˆ·ç«¯ï¼ŒåŒ…å«è¶…æ—¶å’Œå¤§å°é™åˆ¶
	client := &http.Client{
		Timeout: 60 * time.Second, // 1åˆ†é’Ÿè¶…æ—¶
	}

	// åˆ›å»ºè¯·æ±‚
	req, err := http.NewRequestWithContext(ctx, "GET", imageURL, nil)
	if err != nil {
		return "", "", fmt.Errorf("create request failed: %w", err)
	}

	// è®¾ç½®User-Agentï¼Œä¸€äº›ç½‘ç«™éœ€è¦è¿™ä¸ª
	req.Header.Set("User-Agent", "Mozilla/5.0 (compatible; Gemini-Image-Processor/1.0)")

	// å‘èµ·è¯·æ±‚
	resp, err := client.Do(req)
	if err != nil {
		return "", "", fmt.Errorf("download request failed: %w", err)
	}
	defer resp.Body.Close()

	// æ£€æŸ¥HTTPçŠ¶æ€ç 
	if resp.StatusCode != http.StatusOK {
		return "", "", fmt.Errorf("HTTP request failed with status: %d", resp.StatusCode)
	}

	// è·å–Content-Type
	contentType := resp.Header.Get("Content-Type")
	if contentType == "" {
		// å¦‚æœæ²¡æœ‰Content-Typeï¼Œå°è¯•ä»URLæ‰©å±•åæ¨æ–­
		contentType = inferContentTypeFromURL(imageURL)
		if contentType == "" {
			contentType = "application/octet-stream"
		}
	}

	// ä¸é™åˆ¶å›¾ç‰‡ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨è·å–åˆ°çš„Content-Type
	// æŠŠç±»å‹éªŒè¯äº¤ç»™Geminiå®˜æ–¹APIå¤„ç†
	logger.Debugf(ctx, "Content-Type from response: %s", contentType)

	// è®¾ç½®æœ€å¤§ä¸‹è½½å¤§å°ï¼ˆ50MBï¼‰
	const maxImageSize = 50 * 1024 * 1024
	limitedReader := &io.LimitedReader{
		R: resp.Body,
		N: maxImageSize,
	}

	// è¯»å–å›¾ç‰‡å†…å®¹
	imageBytes, err := io.ReadAll(limitedReader)
	if err != nil {
		return "", "", fmt.Errorf("read image data failed: %w", err)
	}

	// æ£€æŸ¥æ˜¯å¦è¶…å‡ºå¤§å°é™åˆ¶
	if limitedReader.N <= 0 {
		return "", "", fmt.Errorf("image size exceeds maximum limit of %d bytes", maxImageSize)
	}

	// è½¬æ¢ä¸ºbase64
	base64Data = base64.StdEncoding.EncodeToString(imageBytes)

	// æ ‡å‡†åŒ–MIMEç±»å‹ï¼Œä½†ä¸é™åˆ¶ç±»å‹
	switch contentType {
	case "image/jpg":
		mimeType = "image/jpeg"
	default:
		mimeType = contentType
	}

	// æ‰€æœ‰ç±»å‹éƒ½è½¬æ¢ä¸ºbase64ï¼Œè®©Geminiå®˜æ–¹APIåˆ¤æ–­æ˜¯å¦æ”¯æŒ

	logger.Debugf(ctx, "Downloaded image: URL=%s, MIME=%s, OriginalSize=%d bytes, Base64Size=%d bytes",
		imageURL, mimeType, len(imageBytes), len(base64Data))

	return base64Data, mimeType, nil
}

// inferContentTypeFromURL ä»URLçš„æ‰©å±•åæ¨æ–­Content-Type
func inferContentTypeFromURL(imageURL string) string {
	// æå–æ–‡ä»¶æ‰©å±•å
	parts := strings.Split(imageURL, "?") // ç§»é™¤æŸ¥è¯¢å‚æ•°
	urlPath := parts[0]

	ext := strings.ToLower(filepath.Ext(urlPath))

	switch ext {
	case ".png":
		return "image/png"
	case ".jpg", ".jpeg":
		return "image/jpeg"
	case ".gif":
		return "image/gif"
	case ".webp":
		return "image/webp"
	case ".bmp":
		return "image/bmp"
	case ".tiff", ".tif":
		return "image/tiff"
	case ".svg":
		return "image/svg+xml"
	case ".ico":
		return "image/x-icon"
	case ".heic":
		return "image/heic"
	case ".avif":
		return "image/avif"
	default:
		return "" // æœªçŸ¥ç±»å‹
	}
}

// processImagesConcurrently å¹¶å‘å¤„ç†å¤šä¸ªå›¾ç‰‡è¾“å…¥
func processImagesConcurrently(ctx context.Context, imageInputs []string) ([]gemini.Part, int) {
	if len(imageInputs) == 0 {
		return []gemini.Part{}, 0
	}

	// è®¾ç½®æœ€å¤§å¹¶å‘æ•°ï¼Œé¿å…åˆ›å»ºè¿‡å¤šgoroutine
	const maxConcurrency = 10
	concurrency := len(imageInputs)
	if concurrency > maxConcurrency {
		concurrency = maxConcurrency
	}

	// åˆ›å»ºç»“æœç»“æ„å’Œchannels
	type imageTask struct {
		index int
		input string
	}

	type imageResult struct {
		index int
		part  gemini.Part
		error error
	}

	// åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœchannel
	taskChan := make(chan imageTask, len(imageInputs))
	resultChan := make(chan imageResult, len(imageInputs))

	startTime := time.Now()
	logger.Infof(ctx, "Starting concurrent processing of %d images with %d workers", len(imageInputs), concurrency)

	// å¡«å……ä»»åŠ¡é˜Ÿåˆ—
	validTasks := 0
	for i, imageInput := range imageInputs {
		if imageInput == "" {
			logger.Debugf(ctx, "Skipping empty image input at index %d", i)
			continue
		}
		taskChan <- imageTask{index: i, input: imageInput}
		validTasks++
	}
	close(taskChan)

	if validTasks == 0 {
		logger.Infof(ctx, "No valid images to process")
		return []gemini.Part{}, 0
	}

	// å¯åŠ¨worker goroutines
	var wg sync.WaitGroup
	for w := 0; w < concurrency; w++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for task := range taskChan {
				logger.Debugf(ctx, "Worker %d processing image %d: starting", workerID, task.index+1)

				part := parseImageInput(ctx, task.input)

				var err error
				if part.InlineData == nil {
					err = fmt.Errorf("failed to parse image input")
					logger.Warnf(ctx, "Worker %d processing image %d: failed", workerID, task.index+1)
				} else {
					logger.Debugf(ctx, "Worker %d processing image %d: success (MIME: %s, size: %d bytes)",
						workerID, task.index+1, part.InlineData.MimeType, len(part.InlineData.Data))
				}

				resultChan <- imageResult{
					index: task.index,
					part:  part,
					error: err,
				}
			}
		}(w)
	}

	// å¯åŠ¨goroutineç­‰å¾…æ‰€æœ‰workerå®Œæˆå¹¶å…³é—­ç»“æœchannel
	go func() {
		wg.Wait()
		close(resultChan)
	}()

	// æ”¶é›†ç»“æœï¼Œä¿æŒåŸå§‹é¡ºåº
	results := make([]gemini.Part, 0, validTasks)
	successCount := 0

	// åˆ›å»ºä¸€ä¸ªä¸´æ—¶mapæ¥å­˜å‚¨ç»“æœï¼Œä»¥ä¾¿æŒ‰åŸå§‹é¡ºåºæ’åˆ—
	resultMap := make(map[int]gemini.Part)

	for result := range resultChan {
		if result.error == nil && result.part.InlineData != nil {
			resultMap[result.index] = result.part
			successCount++
		}
	}

	// æŒ‰åŸå§‹é¡ºåºæ·»åŠ æˆåŠŸçš„ç»“æœ
	for i := range imageInputs {
		if part, exists := resultMap[i]; exists {
			results = append(results, part)
		}
	}

	duration := time.Since(startTime)
	logger.Infof(ctx, "Concurrent image processing completed: %d/%d successful, duration: %v, workers: %d",
		successCount, validTasks, duration, concurrency)

	return results, successCount
}

// updateAliImageTaskStatusFromBody æ›´æ–°é˜¿é‡Œäº‘å›¾ç‰‡ä»»åŠ¡çŠ¶æ€åˆ°æ•°æ®åº“
func updateAliImageTaskStatusFromBody(taskId string, responseBody []byte, imageTask *model.Image) {
	// è§£æé˜¿é‡Œäº‘å“åº”ç»“æ„
	var aliResponse struct {
		RequestId string `json:"request_id,omitempty"`
		Output    struct {
			TaskId        string `json:"task_id,omitempty"`
			TaskStatus    string `json:"task_status,omitempty"`
			SubmitTime    string `json:"submit_time,omitempty"`
			ScheduledTime string `json:"scheduled_time,omitempty"`
			EndTime       string `json:"end_time,omitempty"`
			Results       []struct {
				OrigPrompt string `json:"orig_prompt,omitempty"`
				URL        string `json:"url,omitempty"`
				Code       string `json:"code,omitempty"`
				Message    string `json:"message,omitempty"`
			} `json:"results,omitempty"`
			Code    string `json:"code,omitempty"`
			Message string `json:"message,omitempty"`
		} `json:"output,omitempty"`
		Code    string `json:"code,omitempty"`
		Message string `json:"message,omitempty"`
	}

	if err := json.Unmarshal(responseBody, &aliResponse); err != nil {
		logger.Errorf(context.Background(), "Failed to unmarshal ali response for status update: %v", err)
		return
	}

	var taskStatus = aliResponse.Output.TaskStatus
	var failReason string
	var imageUrls []string

	// æå–å¤±è´¥åŸå› 
	if taskStatus == "FAILED" {
		if aliResponse.Output.Message != "" {
			failReason = aliResponse.Output.Message
		}
	}

	// æå–æˆåŠŸçš„å›¾ç‰‡URL
	for _, result := range aliResponse.Output.Results {
		if result.URL != "" {
			imageUrls = append(imageUrls, result.URL)
		}
	}

	// æ˜ å°„é˜¿é‡Œäº‘çŠ¶æ€åˆ°æ•°æ®åº“çŠ¶æ€
	dbStatus := mapAliStatusToDbStatus(taskStatus)

	// è®°å½•åŸå§‹çŠ¶æ€ç”¨äºé€€æ¬¾åˆ¤æ–­
	oldStatus := imageTask.Status

	// æ›´æ–°çŠ¶æ€
	imageTask.Status = dbStatus

	// å¦‚æœå¤±è´¥ï¼Œæ›´æ–°å¤±è´¥åŸå› 
	if taskStatus == "FAILED" || taskStatus == "UNKNOWN" || taskStatus == "CANCELED" {
		if failReason != "" {
			imageTask.FailReason = failReason
		} else {
			imageTask.FailReason = fmt.Sprintf("Task failed with status: %s", taskStatus)
		}
	} else {
		// æ¸…é™¤å¤±è´¥åŸå› ï¼ˆå¦‚æœçŠ¶æ€ä¸æ˜¯å¤±è´¥ï¼‰
		imageTask.FailReason = ""
	}

	// å¦‚æœæˆåŠŸä¸”æœ‰å›¾ç‰‡URLï¼Œæ›´æ–°å­˜å‚¨URL
	if taskStatus == "SUCCEEDED" && len(imageUrls) > 0 {
		// å°†URLæ•°ç»„JSONåŒ–ä¸ºå­—ç¬¦ä¸²å­˜å‚¨
		if urlsJson, err := json.Marshal(imageUrls); err == nil {
			imageTask.StoreUrl = string(urlsJson)
		} else {
			// å¦‚æœJSONåŒ–å¤±è´¥ï¼Œè‡³å°‘ä¿å­˜ç¬¬ä¸€ä¸ªURL
			imageTask.StoreUrl = imageUrls[0]
		}
	}

	// æ£€æŸ¥æ˜¯å¦éœ€è¦é€€æ¬¾ï¼šåªæœ‰å½“çŠ¶æ€ä»éå¤±è´¥å˜ä¸ºå¤±è´¥æ—¶æ‰é€€æ¬¾
	needRefund := (oldStatus != "failed" && oldStatus != "cancelled") &&
		(dbStatus == "failed" || dbStatus == "cancelled")

	// ä¿å­˜åˆ°æ•°æ®åº“
	err := model.DB.Model(&model.Image{}).Where("task_id = ?", taskId).Updates(imageTask).Error
	if err != nil {
		logger.Errorf(context.Background(), "Failed to update ali image task status for %s: %v", taskId, err)
	} else {
		logger.Infof(context.Background(), "Updated ali image task %s status from '%s' to '%s'",
			taskId, oldStatus, dbStatus)

		if needRefund {
			// å¦‚æœéœ€è¦é€€æ¬¾ï¼Œæ‰§è¡Œé€€æ¬¾
			logger.Warnf(context.Background(), "Ali image task %s needs refund: status changed from '%s' to '%s'",
				taskId, oldStatus, dbStatus)
			compensateAliImageTask(taskId)
		}
	}
}

// mapAliStatusToDbStatus æ˜ å°„é˜¿é‡Œäº‘APIçŠ¶æ€åˆ°æ•°æ®åº“çŠ¶æ€
func mapAliStatusToDbStatus(aliStatus string) string {
	switch aliStatus {
	case "PENDING":
		return "pending"
	case "RUNNING":
		return "running"
	case "SUCCEEDED":
		return "succeeded"
	case "FAILED":
		return "failed"
	case "CANCELED":
		return "cancelled"
	case "UNKNOWN":
		return "failed" // å°†UNKNOWNè§†ä¸ºå¤±è´¥
	default:
		return "processing" // æœªçŸ¥çŠ¶æ€é»˜è®¤ä¸ºå¤„ç†ä¸­
	}
}

// compensateAliImageTask è¡¥å¿é˜¿é‡Œäº‘å›¾ç‰‡ä»»åŠ¡å¤±è´¥çš„é…é¢
func compensateAliImageTask(taskId string) {
	// è·å–ä»»åŠ¡è¯¦æƒ…
	imageTask, err := model.GetImageByTaskId(taskId)
	if err != nil {
		logger.Errorf(context.Background(), "Failed to get ali image task for compensation: %v", err)
		return
	}

	if imageTask.Quota <= 0 {
		logger.Warnf(context.Background(), "Ali image task %s has no quota to refund", taskId)
		return
	}

	logger.Infof(context.Background(), "Compensating user %d for failed ali image task %s with quota %d",
		imageTask.UserId, taskId, imageTask.Quota)

	// 1. è¡¥å¿ç”¨æˆ·é…é¢ï¼ˆå¢åŠ ä½™é¢ã€å‡å°‘å·²ä½¿ç”¨é…é¢å’Œè¯·æ±‚æ¬¡æ•°ï¼‰
	err = model.CompensateVideoTaskQuota(imageTask.UserId, imageTask.Quota)
	if err != nil {
		logger.Errorf(context.Background(), "Failed to compensate user quota for ali image task %s: %v", taskId, err)
		return
	}
	logger.Infof(context.Background(), "Successfully compensated user %d quota for ali image task %s",
		imageTask.UserId, taskId)

	// 2. è¡¥å¿æ¸ é“é…é¢ï¼ˆå‡å°‘æ¸ é“å·²ä½¿ç”¨é…é¢ï¼‰
	err = model.CompensateChannelQuota(imageTask.ChannelId, imageTask.Quota)
	if err != nil {
		logger.Errorf(context.Background(), "Failed to compensate channel quota for ali image task %s: %v", taskId, err)
	} else {
		logger.Infof(context.Background(), "Successfully compensated channel %d quota for ali image task %s",
			imageTask.ChannelId, taskId)
	}

	// æ›´æ–°ç”¨æˆ·é…é¢ç¼“å­˜
	err = model.CacheUpdateUserQuota(context.Background(), imageTask.UserId)
	if err != nil {
		logger.Errorf(context.Background(), "Failed to update user quota cache after compensation: %v", err)
	}

	logger.Infof(context.Background(), "Successfully completed compensation for ali image task %s: user %d and channel %d restored quota %d",
		taskId, imageTask.UserId, imageTask.ChannelId, imageTask.Quota)
}

// convertSizeToAspectRatio å°† OpenAI æ ¼å¼çš„å°ºå¯¸è½¬æ¢ä¸º Gemini çš„å®½é«˜æ¯”æ ¼å¼
// æ”¯æŒä¸¤ç§è¾“å…¥æ ¼å¼ï¼š
// 1. æ¯”ä¾‹æ ¼å¼ï¼ˆåŒ…å«":"ï¼‰ï¼šå¦‚ "16:9" -> ç›´æ¥èµ‹å€¼è¿”å› "16:9"
// 2. å°ºå¯¸æ ¼å¼ï¼ˆåŒ…å«"x"ï¼‰ï¼šå¦‚ "1024x1024" -> è½¬æ¢ä¸º "1:1"
// è¿”å›ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ— æ³•è¯†åˆ«çš„æ ¼å¼ï¼Œè°ƒç”¨æ–¹åº”ä¸ä¼ é€’æ­¤å‚æ•°
func convertSizeToAspectRatio(size string) string {
	// åˆ¤æ–­æ˜¯æ¯”ä¾‹æ ¼å¼ï¼ˆåŒ…å«å†’å·ï¼‰è¿˜æ˜¯å°ºå¯¸æ ¼å¼ï¼ˆåŒ…å«xï¼‰
	if strings.Contains(size, ":") {
		// å·²ç»æ˜¯æ¯”ä¾‹æ ¼å¼ï¼Œç›´æ¥è¿”å›
		return size
	} else if strings.Contains(size, "x") || strings.Contains(size, "X") {
		// æ˜¯å°ºå¯¸æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºæ¯”ä¾‹

		// å®šä¹‰å¸¸è§å°ºå¯¸åˆ°å®½é«˜æ¯”çš„æ˜ å°„è¡¨
		sizeToRatioMap := map[string]string{
			"1024x1024": "1:1",
			"832x1248":  "2:3",
			"1248x832":  "3:2",
			"864x1184":  "3:4",
			"1184x864":  "4:3",
			"896x1152":  "4:5",
			"1152x896":  "5:4",
			"768x1344":  "9:16",
			"1344x768":  "16:9",
			"1536x672":  "21:9",
		}

		// å…ˆæŸ¥æ‰¾æ˜ å°„è¡¨
		if ratio, exists := sizeToRatioMap[size]; exists {
			return ratio
		}

		// å¦‚æœä¸åœ¨æ˜ å°„è¡¨ä¸­ï¼Œå°è¯•åŠ¨æ€è§£æå¹¶è®¡ç®—æ¯”ä¾‹
		parts := strings.Split(strings.ToLower(size), "x")
		if len(parts) == 2 {
			width, err1 := strconv.Atoi(strings.TrimSpace(parts[0]))
			height, err2 := strconv.Atoi(strings.TrimSpace(parts[1]))
			if err1 == nil && err2 == nil && width > 0 && height > 0 {
				// è®¡ç®—æœ€å¤§å…¬çº¦æ•°
				gcd := func(a, b int) int {
					for b != 0 {
						a, b = b, a%b
					}
					return a
				}
				divisor := gcd(width, height)
				return fmt.Sprintf("%d:%d", width/divisor, height/divisor)
			}
		}
	}

	// å¦‚æœæ— æ³•è§£ææˆ–æ ¼å¼ä¸æ­£ç¡®ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºä¸è®¾ç½®æ­¤å‚æ•°
	// Gemini å®˜æ–¹é»˜è®¤ä¼šä½¿è¾“å‡ºå›¾ç‰‡çš„å¤§å°ä¸è¾“å…¥å›¾ç‰‡çš„å¤§å°ä¿æŒä¸€è‡´
	return ""
}
